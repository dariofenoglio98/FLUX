{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5 (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found or corrupted. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m         test(model, device, test_loader)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[83], line 117\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# reduce the dimension of training data\u001b[39;00m\n\u001b[1;32m    116\u001b[0m train_dataset\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mdata[:\u001b[38;5;241m5000\u001b[39m]\n\u001b[0;32m--> 117\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    119\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mtest_batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torchvision/datasets/cifar.py:69\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain:\n\u001b[1;32m     72\u001b[0m     downloaded_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_list\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found or corrupted. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Define the LeNet-5 architecture\n",
    "# class LeNet5(nn.Module):\n",
    "#     def __init__(self, in_channels=1, num_classes=10):\n",
    "#         super(LeNet5, self).__init__()\n",
    "#         self.num_classes = num_classes\n",
    "#         self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "#         self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "#         self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "#         self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "#         # These layers depend on the input size\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Fully connected layer, output size 120\n",
    "#         self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "#         self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "#         x = self.pool1(x)  # Apply subsampling pool1\n",
    "#         x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "#         x = self.pool2(x)  # Apply subsampling pool2\n",
    "#         x = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "#         x = F.relu(self.fc1(x))  # Apply ReLU after fc1\n",
    "#         x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "#         x = self.fc3(x)  # Output layer\n",
    "#         return x\n",
    "\n",
    "# Define a function to train the model\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if batch_idx % 100 == 0:\n",
    "        #     print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "        #           f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Define a function to test the model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    latent_all = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, latent = model(data, latent=True)\n",
    "            latent_all.append(latent.cpu().numpy())\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "    \n",
    "    latent_all = np.concatenate(latent_all, axis=0)\n",
    "    latent_mean = np.mean(latent_all, axis=0)\n",
    "    print(f\"Latent Mean: {np.mean(latent_mean)}, Latent Std: {np.std(latent_mean)}, Latent Max: {np.max(latent_mean)}, Latent Min: {np.min(latent_mean)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "# define device\n",
    "def check_gpu(manual_seed=True, print_info=True):\n",
    "    if manual_seed:\n",
    "        torch.manual_seed(0)\n",
    "    if torch.cuda.is_available():\n",
    "        if print_info:\n",
    "            print(\"CUDA is available\")\n",
    "        device = 'cuda'\n",
    "        torch.cuda.manual_seed_all(0) \n",
    "    elif torch.backends.mps.is_available():\n",
    "        if print_info:\n",
    "            print(\"MPS is available\")\n",
    "        device = torch.device(\"mps\")\n",
    "        torch.mps.manual_seed(0)\n",
    "    else:\n",
    "        if print_info:\n",
    "            print(\"CUDA is not available\")\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "# Main function to run the training and testing\n",
    "def main():\n",
    "    # Training settings\n",
    "    batch_size = 128\n",
    "    test_batch_size = 1000\n",
    "    epochs = 100\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    no_cuda = False\n",
    "    seed = 1\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    # reduce the dimension of training data\n",
    "    train_dataset.data = train_dataset.data[:5000]\n",
    "    test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    model = LeNet5(in_channels=1, num_classes=10).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "\n",
      "Test set: Average loss: 0.6712, Accuracy: 7651/10000 (77%)\n",
      "\n",
      "Latent Mean: 1.3499350547790527, Latent Std: 0.9161264300346375, Latent Max: 8.477176666259766, Latent Min: 0.08574561774730682\n",
      "\n",
      "Test set: Average loss: 0.2537, Accuracy: 9252/10000 (93%)\n",
      "\n",
      "Latent Mean: 0.972943902015686, Latent Std: 0.4720045030117035, Latent Max: 3.5702555179595947, Latent Min: 0.057498980313539505\n",
      "\n",
      "Test set: Average loss: 0.1920, Accuracy: 9399/10000 (94%)\n",
      "\n",
      "Latent Mean: 1.0231431722640991, Latent Std: 0.5263200402259827, Latent Max: 4.648538112640381, Latent Min: 0.052269477397203445\n",
      "\n",
      "Test set: Average loss: 0.1836, Accuracy: 9430/10000 (94%)\n",
      "\n",
      "Latent Mean: 0.9468675851821899, Latent Std: 0.45056429505348206, Latent Max: 3.0544557571411133, Latent Min: 0.05543508753180504\n",
      "\n",
      "Test set: Average loss: 0.1670, Accuracy: 9477/10000 (95%)\n",
      "\n",
      "Latent Mean: 0.9960904121398926, Latent Std: 0.4929356276988983, Latent Max: 3.220304012298584, Latent Min: 0.05475081875920296\n",
      "\n",
      "Test set: Average loss: 0.1155, Accuracy: 9661/10000 (97%)\n",
      "\n",
      "Latent Mean: 1.009360909461975, Latent Std: 0.5070521831512451, Latent Max: 3.630603790283203, Latent Min: 0.0598457045853138\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 154\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    153\u001b[0m     train(model, device, train_loader, optimizer, epoch)\n\u001b[0;32m--> 154\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[83], line 62\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader)\u001b[0m\n\u001b[1;32m     60\u001b[0m         test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output, target, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# sum up batch loss\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# get the index of the max log-probability\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m test_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest set: Average loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_loader\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     66\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100.\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mcorrect\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(test_loader\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    " \n",
    "# Training settings\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "epochs = 100\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "no_cuda = False\n",
    "seed = 1\n",
    "\n",
    "device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "# take the first 1000 samples\n",
    "train_dataset.data = train_dataset.data[:2000]\n",
    "test_dataset = datasets.MNIST('../data', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "# Define the LeNet-5 architecture\n",
    "# LeNet-5 model\n",
    "from math import prod\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10, input_size=(28, 28)):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "        # Dinamically calculate the size of the features after convolutional layers\n",
    "        dummy_input = torch.zeros(1, in_channels, *input_size)\n",
    "        dummy_output = self.pool2(self.conv2(self.pool1(self.conv1(dummy_input))))\n",
    "        self.feature_size = prod(dummy_output.size()[1:])\n",
    "\n",
    "        self.fc1 = nn.Linear(self.feature_size, 120)  # Fully connected layer, output size 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "    def forward(self, x, latent=False):\n",
    "        x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "        x = self.pool1(x)  # Apply subsampling pool1\n",
    "        x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "        x = self.pool2(x)  # Apply subsampling pool2\n",
    "        x_l = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "        x = F.relu(self.fc1(x_l))  # Apply ReLU after fc1\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        if latent:\n",
    "            return x, x_l\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "# LeNet-5 model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10, input_size=(28, 28)):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "        # Dinamically calculate the size of the features after convolutional layers\n",
    "        dummy_input = torch.zeros(1, in_channels, *input_size)\n",
    "        dummy_output = self.pool2(self.conv2(self.pool1(self.conv1(dummy_input))))\n",
    "        self.feature_size = prod(dummy_output.size()[1:])\n",
    "\n",
    "        self.fc1 = nn.Linear(self.feature_size, 120)  # Fully connected layer, output size 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "    def forward(self, x, latent=False):\n",
    "        x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "        x = self.pool1(x)  # Apply subsampling pool1\n",
    "        x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "        x = self.pool2(x)  # Apply subsampling pool2\n",
    "        x_l = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "        x = F.relu(self.fc1(x_l))  # Apply ReLU after fc1\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        if latent:\n",
    "            return x, x_l\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "\n",
    "# Resnet-9 layer\n",
    "def residual_block(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    ]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# ResNet-9 model\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, input_size=(28, 28)):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.prep = residual_block(in_channels, 64)\n",
    "        self.layer1_head = residual_block(64, 128, pool=True)\n",
    "        self.layer1_residual = nn.Sequential(residual_block(128, 128), residual_block(128, 128))\n",
    "        self.layer2 = residual_block(128, 256, pool=True)\n",
    "        self.layer3_head = residual_block(256, 512, pool=True)\n",
    "        self.layer3_residual = nn.Sequential(residual_block(512, 512), residual_block(512, 512))\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Changed to adaptive average pooling:         self.MaxPool2d = nn.Sequential(nn.MaxPool2d(4))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Calculate the size of the features after the convolutional layers\n",
    "        dummy_input = torch.zeros(1, in_channels, *input_size)\n",
    "        dummy_output = self.pool(self.layer3_head(self.layer2(self.layer1_head(self.prep(dummy_input)))))\n",
    "        self.feature_size = dummy_output.size(1) * dummy_output.size(2) * dummy_output.size(3)\n",
    "\n",
    "        # Output layer\n",
    "        self.linear = nn.Linear(self.feature_size, num_classes)\n",
    "\n",
    "    def forward(self, x, latent=False):\n",
    "        x = self.prep(x)\n",
    "        x = self.layer1_head(x)\n",
    "        x = self.layer1_residual(x) + x\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3_head(x)\n",
    "        x = self.layer3_residual(x) + x\n",
    "        x = self.pool(x)  # Changed to adaptive average pooling\n",
    "        x_l = x.view(x.size(0), -1)\n",
    "        x = self.linear(x_l)\n",
    "        if latent:\n",
    "            return x, x_l\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "\n",
    "model = ResNet9(in_channels=1, num_classes=10).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import minmaxscaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ModelEvaluator class\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, test_loader, device):\n",
    "        \"\"\"\n",
    "        Initializes the ModelEvaluator with the model, device, and number of classes.\n",
    "        \n",
    "        Args:\n",
    "            test_loader: DataLoader with test data\n",
    "            device: Device to run the evaluation on\n",
    "        \"\"\"\n",
    "        \n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        self.criterion_trad = torch.nn.CrossEntropyLoss() \n",
    "        \n",
    "\n",
    "    def evaluate(self, model, latent=False, max_latent_space=None):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the provided test data and returns various metrics.\n",
    "\n",
    "        Args:\n",
    "            model: Model to evaluate\n",
    "            latent: Whether to return the latent representation of the test data\n",
    "        \"\"\"\n",
    "        \n",
    "        # client-enhanced evaluation function\n",
    "        # def evaluate_model_per_class(model, device, test_loader, latent=False):\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        num_classes = model.num_classes\n",
    "\n",
    "        # Initialize storage for metrics\n",
    "        precision_per_class = [0] * num_classes\n",
    "        recall_per_class = [0] * num_classes\n",
    "        f1_per_class = [0] * num_classes\n",
    "        accuracy_per_class = [0] * num_classes\n",
    "        loss_per_class = [0] * num_classes\n",
    "        class_counts = [0] * num_classes\n",
    "\n",
    "        y_true_all = []\n",
    "        y_pred_all = []\n",
    "        loss_all = []\n",
    "        latent_all = []\n",
    "        latent_mean = []\n",
    "        loss_trad = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Accumulate predictions and targets over batches\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                \n",
    "                # Get model predictions\n",
    "                if latent: \n",
    "                    output, latent_space = model(data, latent=True)\n",
    "                    latent_all.extend(latent_space.cpu().numpy())\n",
    "                else: \n",
    "                    output = model(data) \n",
    "                    \n",
    "                y_pred_batch = output.argmax(dim=1, keepdim=False)  # Predicted class labels\n",
    "                \n",
    "                # Store the true and predicted labels for the batch\n",
    "                y_true_all.extend(target.cpu().numpy())\n",
    "                y_pred_all.extend(y_pred_batch.cpu().numpy())\n",
    "                \n",
    "                # Compute per-sample loss for the batch\n",
    "                batch_loss = self.criterion(output, target).cpu().numpy()\n",
    "                loss_all.extend(batch_loss)\n",
    "                \n",
    "                # Compute traditional loss for the batch\n",
    "                loss_trad += self.criterion_trad(output, target).item()\n",
    "                \n",
    "                # Accumulate the total number of samples\n",
    "                total_samples += len(target)\n",
    "\n",
    "        # Convert collected predictions and true labels into tensors for processing\n",
    "        y_true_all = torch.tensor(y_true_all)\n",
    "        y_pred_all = torch.tensor(y_pred_all)\n",
    "        loss_all = torch.tensor(loss_all)\n",
    "        \n",
    "        # Average traditional loss over the total number of samples\n",
    "        loss_trad /= total_samples\n",
    "        \n",
    "        # Calculate traditional accuracy on the entire test set\n",
    "        accuracy_trad = accuracy_score(y_true_all, y_pred_all)\n",
    "        \n",
    "        # Average latent\n",
    "        if latent:\n",
    "            latent_all = np.array(latent_all)\n",
    "            print(f\"Shape of latent_all before PCA: {latent_all.shape}\")\n",
    "            # SCALE OR NOT TRY BOTH\n",
    "            # scaler = MinMaxScaler(feature_range=(0, max_latent_space)) # maybe try also StandardScaler\n",
    "            # latent_all = scaler.fit_transform(latent_all) # Sample, Dim_latent_space\n",
    "            # print(f\"Min-Max values of latent_all: {np.min(latent_all)}, {np.max(latent_all)}\")\n",
    "            # create random_points to fit PCA (min=0, max=max_latent_space)\n",
    "            np.random.seed(seed=1)\n",
    "            random_points = np.random.uniform(0, max_latent_space+2, size=(200, latent_all.shape[1]))\n",
    "            pca = PCA(n_components=num_classes)\n",
    "            # fit PCA on random_points\n",
    "            pca.fit(random_points)\n",
    "            # transform latent_all\n",
    "            latent_all = pca.transform(latent_all)\n",
    "            print(f\"Shape of latent_all after PCA: {latent_all.shape}\")\n",
    "            # Mean on first dimension\n",
    "            latent_mean = np.mean(latent_all, axis=0)\n",
    "            print(f\"shape of latent_mean: {latent_mean.shape}\")\n",
    "            \n",
    "        # Iterate through each class (for MNIST, classes are 0 to 9 by default)\n",
    "        for class_idx in range(num_classes):\n",
    "            # Get all predictions and ground truths for the current class\n",
    "            class_mask = (y_true_all == class_idx)  # Mask for this class\n",
    "            \n",
    "            y_true_class = (y_true_all == class_idx).numpy().astype(int)  # Binary labels for the current class\n",
    "            y_pred_class = (y_pred_all == class_idx).numpy().astype(int)  # Binary predictions for the current class\n",
    "            \n",
    "            # Only calculate if there are samples for this class\n",
    "            if class_mask.sum() > 0:\n",
    "                # Compute precision, recall, and F1-score for this class\n",
    "                precision = precision_score(y_true_class, y_pred_class, zero_division=0)\n",
    "                recall = recall_score(y_true_class, y_pred_class, zero_division=0)\n",
    "                f1 = f1_score(y_true_class, y_pred_class, zero_division=0)\n",
    "                accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "\n",
    "                # Compute the loss for this class (average the loss of samples in this class)\n",
    "                class_loss = loss_all[class_mask].mean().item()\n",
    "\n",
    "                # Update class counts and metrics\n",
    "                precision_per_class[class_idx] = precision\n",
    "                recall_per_class[class_idx] = recall\n",
    "                f1_per_class[class_idx] = f1\n",
    "                accuracy_per_class[class_idx] = accuracy\n",
    "                loss_per_class[class_idx] = class_loss\n",
    "                class_counts[class_idx] = class_mask.sum().item()\n",
    "\n",
    "        return loss_trad, accuracy_trad, precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class, latent_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of latent_all before PCA: (10000, 512)\n",
      "Min-Max values of latent_all: 0.0, 2.000000238418579\n",
      "Shape of latent_all after PCA: (10000, 10)\n",
      "shape of latent_mean: (10,)\n",
      "Traditional Loss: 0.0023003185749053954, Traditional Accuracy: 0.14\n",
      "Precision: [0.0, 0.13983739837398373, 0.0, 0.19558011049723756, 0.0, 0.0, 0.3333333333333333, 0.058823529411764705, 0.0, 0.10477299185098952]\n",
      "Recall: [0.0, 0.9850220264317181, 0.0, 0.17524752475247524, 0.0, 0.0, 0.0010438413361169101, 0.013618677042801557, 0.0, 0.08919722497522299]\n",
      "F1: [0.0, 0.24490690032858708, 0.0, 0.18485639686684074, 0.0, 0.0, 0.002081165452653486, 0.022116903633491312, 0.0, 0.09635974304068523]\n",
      "Accuracy: [0.902, 0.3106, 0.8968, 0.8439, 0.9018, 0.9108, 0.9041, 0.8762, 0.9026, 0.8312]\n",
      "Loss: [2.3571455478668213, 2.2325198650360107, 2.3182084560394287, 2.2502312660217285, 2.344841718673706, 2.4055612087249756, 2.2774877548217773, 2.2644283771514893, 2.3214900493621826, 2.254664659500122]\n",
      "Latent Mean: 0.013517613615449448, Latent Std: 0.3815882009298418, Latent Max: 0.6107625107736734, Latent Min: -0.6021221324248819\n"
     ]
    }
   ],
   "source": [
    "model = ResNet9(in_channels=1, num_classes=10).to(device)\n",
    "evaluator = ModelEvaluator(test_loader, device)\n",
    "loss_trad, accuracy_trad, precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class, latent_all = evaluator.evaluate(model, latent=True, max_latent_space=2)\n",
    "print(f\"Traditional Loss: {loss_trad}, Traditional Accuracy: {accuracy_trad}\")\n",
    "print(f\"Precision: {precision_per_class}\")\n",
    "print(f\"Recall: {recall_per_class}\")\n",
    "print(f\"F1: {f1_per_class}\")\n",
    "print(f\"Accuracy: {accuracy_per_class}\")\n",
    "print(f\"Loss: {loss_per_class}\")\n",
    "print(f\"Latent Mean: {np.mean(latent_all)}, Latent Std: {np.std(latent_all)}, Latent Max: {np.max(latent_all)}, Latent Min: {np.min(latent_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.16221555372172541,\n",
       " 0.19649889612940588,\n",
       " 0.14639664684456435,\n",
       " 0.6107625107736734,\n",
       " -0.3436018100599132,\n",
       " 0.17317741542740847,\n",
       " 0.535733507743075,\n",
       " 0.02791765854889959,\n",
       " -0.6021221324248819,\n",
       " -0.4473710031060118]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(latent_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No client CID provided. Skipping the submission.\n"
     ]
    }
   ],
   "source": [
    "# if client list not define, print\n",
    "if not 'client_list' in locals():\n",
    "    print(\"No client CID provided. Skipping the submission.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.9918533604887984, 0.9964726631393298, 0.9940711462450593, 0.9776264591439688, 0.9957850368809273, 0.9746136865342163, 0.9968051118210862, 0.9551820728291317, 0.997907949790795, 0.9696969696969697]'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(precision_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # standard scaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    num_classes = model.num_classes\n",
    "    latent = True\n",
    "\n",
    "    # Define the cross-entropy loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    criterion_trad = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    precision_per_class = [0] * num_classes\n",
    "    recall_per_class = [0] * num_classes\n",
    "    f1_per_class = [0] * num_classes\n",
    "    accuracy_per_class = [0] * num_classes\n",
    "    loss_per_class = [0] * num_classes\n",
    "    class_counts = [0] * num_classes\n",
    "\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    loss_all = []\n",
    "    latent_all = []\n",
    "    loss_trad = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Accumulate predictions and targets over batches\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get model predictions\n",
    "            if latent: \n",
    "                output, latent_space = model(data, latent=True)\n",
    "                latent_all.extend(latent_space.cpu().numpy())\n",
    "            else: \n",
    "                output = model(data) \n",
    "                \n",
    "            y_pred_batch = output.argmax(dim=1, keepdim=False)  # Predicted class labels\n",
    "            \n",
    "            # Store the true and predicted labels for the batch\n",
    "            y_true_all.extend(target.cpu().numpy())\n",
    "            y_pred_all.extend(y_pred_batch.cpu().numpy())\n",
    "            \n",
    "            # Compute per-sample loss for the batch\n",
    "            batch_loss = criterion(output, target).cpu().numpy()\n",
    "            loss_all.extend(batch_loss)\n",
    "            \n",
    "            # Compute traditional loss for the batch\n",
    "            loss_trad += criterion_trad(output, target).item()\n",
    "            \n",
    "            # Accumulate the total number of samples\n",
    "            total_samples += len(target)\n",
    "\n",
    "    # Convert collected predictions and true labels into tensors for processing\n",
    "    y_true_all = torch.tensor(y_true_all)\n",
    "    y_pred_all = torch.tensor(y_pred_all)\n",
    "    loss_all = torch.tensor(loss_all)\n",
    "    \n",
    "    # Average traditional loss over the total number of samples\n",
    "    loss_trad /= total_samples\n",
    "    \n",
    "    # Calculate traditional accuracy on the entire test set\n",
    "    accuracy_trad = accuracy_score(y_true_all, y_pred_all)\n",
    "    \n",
    "    # normalize latent space\n",
    "    latent_all = np.array(latent_all)\n",
    "    latent_all = latent_all.mean(axis=0)\n",
    "    scaler.fit(latent_all.reshape(-1, 1))\n",
    "    latent_all = scaler.transform(latent_all.reshape(-1, 1))\n",
    "    \n",
    "    # PCA\n",
    "    rand_points = torch.normal(mean=0, std=1, size=(100, latent_all.shape[1]))\n",
    "    pca_model = PCA(n_components=30)\n",
    "    \n",
    "    # # Average latent\n",
    "    # if latent:\n",
    "    #     latent_all = torch.tensor(latent_all)\n",
    "    #     latent_all = latent_all.view(latent_all.size(0), -1)\n",
    "    #     latent_all = latent_all.mean(dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        rand_points = torch.normal(mean=0, std=0.1, size=(100, errors.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.9790297], dtype=float32),\n",
       " array([-1.2622539], dtype=float32),\n",
       " 0.99999994,\n",
       " -1.8626451e-09)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# latent_all = np.array(latent_all)\n",
    "# average latent space along the samples\n",
    "# latent_all_mean = latent_all.mean(axis=0)\n",
    "max(latent_all), min(latent_all), np.std(latent_all), np.mean(latent_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-wise evaluation:\n",
      "Class 0: Precision = 0.9797, Recall = 0.9837, F1 = 0.9817, Accuracy = 0.9964, Loss = 0.0577\n",
      "Class 1: Precision = 0.9868, Recall = 0.9877, F1 = 0.9872, Accuracy = 0.9971, Loss = 0.0401\n",
      "Class 2: Precision = 0.9488, Recall = 0.9874, F1 = 0.9677, Accuracy = 0.9932, Loss = 0.0427\n",
      "Class 3: Precision = 0.9446, Recall = 0.9792, F1 = 0.9616, Accuracy = 0.9921, Loss = 0.0633\n",
      "Class 4: Precision = 0.9747, Recall = 0.9827, F1 = 0.9787, Accuracy = 0.9958, Loss = 0.0559\n",
      "Class 5: Precision = 0.9593, Recall = 0.9776, F1 = 0.9684, Accuracy = 0.9943, Loss = 0.0750\n",
      "Class 6: Precision = 0.9874, Recall = 0.9781, F1 = 0.9827, Accuracy = 0.9967, Loss = 0.0676\n",
      "Class 7: Precision = 0.9792, Recall = 0.9601, F1 = 0.9695, Accuracy = 0.9938, Loss = 0.1321\n",
      "Class 8: Precision = 0.9788, Recall = 0.9476, F1 = 0.9630, Accuracy = 0.9929, Loss = 0.1553\n",
      "Class 9: Precision = 0.9865, Recall = 0.9386, F1 = 0.9619, Accuracy = 0.9925, Loss = 0.1915\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def evaluate_model_per_class(model, device, test_loader, num_classes=10):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Define the cross-entropy loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    precision_per_class = [0] * num_classes\n",
    "    recall_per_class = [0] * num_classes\n",
    "    f1_per_class = [0] * num_classes\n",
    "    accuracy_per_class = [0] * num_classes\n",
    "    loss_per_class = [0] * num_classes\n",
    "    class_counts = [0] * num_classes\n",
    "\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    loss_all = []\n",
    "\n",
    "    # Accumulate predictions and targets over batches\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get model predictions\n",
    "            output = model(data)\n",
    "            y_pred_batch = output.argmax(dim=1, keepdim=False)  # Predicted class labels\n",
    "            \n",
    "            # Store the true and predicted labels for the batch\n",
    "            y_true_all.extend(target.cpu().numpy())\n",
    "            y_pred_all.extend(y_pred_batch.cpu().numpy())\n",
    "            \n",
    "            # Compute per-sample loss for the batch\n",
    "            batch_loss = criterion(output, target).cpu().numpy()\n",
    "            loss_all.extend(batch_loss)\n",
    "\n",
    "    # Convert collected predictions and true labels into tensors for processing\n",
    "    y_true_all = torch.tensor(y_true_all)\n",
    "    y_pred_all = torch.tensor(y_pred_all)\n",
    "    loss_all = torch.tensor(loss_all)\n",
    "\n",
    "    # Iterate through each class (for MNIST, classes are 0 to 9 by default)\n",
    "    for class_idx in range(num_classes):\n",
    "        # Get all predictions and ground truths for the current class\n",
    "        class_mask = (y_true_all == class_idx)  # Mask for this class\n",
    "        \n",
    "        y_true_class = (y_true_all == class_idx).numpy().astype(int)  # Binary labels for the current class\n",
    "        y_pred_class = (y_pred_all == class_idx).numpy().astype(int)  # Binary predictions for the current class\n",
    "        \n",
    "        # Only calculate if there are samples for this class\n",
    "        if class_mask.sum() > 0:\n",
    "            # Compute precision, recall, and F1-score for this class\n",
    "            precision = precision_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            recall = recall_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            f1 = f1_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "\n",
    "            # Compute the loss for this class (average the loss of samples in this class)\n",
    "            class_loss = loss_all[class_mask].mean().item()\n",
    "\n",
    "            # Update class counts and metrics\n",
    "            precision_per_class[class_idx] = precision\n",
    "            recall_per_class[class_idx] = recall\n",
    "            f1_per_class[class_idx] = f1\n",
    "            accuracy_per_class[class_idx] = accuracy\n",
    "            loss_per_class[class_idx] = class_loss\n",
    "            class_counts[class_idx] = class_mask.sum().item()\n",
    "\n",
    "    return precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class\n",
    "\n",
    "precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class, loss_all = evaluate_model_per_class(model, device, test_loader)\n",
    "print(\"Class-wise evaluation:\")\n",
    "for class_idx in range(10):\n",
    "    print(f\"Class {class_idx}: Precision = {precision_per_class[class_idx]:.4f}, Recall = {recall_per_class[class_idx]:.4f}, F1 = {f1_per_class[class_idx]:.4f}, Accuracy = {accuracy_per_class[class_idx]:.4f}, Loss = {loss_per_class[class_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1629e-03, 1.5663e-04, 5.1977e-03,  ..., 7.3909e-06, 3.2062e-04,\n",
       "        8.0701e-05])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class \u001b[38;5;241m=\u001b[39m \u001b[43mclient_enhanced_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision per class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision_per_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 28\u001b[0m, in \u001b[0;36mclient_enhanced_evaluation\u001b[0;34m(model, device, test_loader)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate the loss for each sample\u001b[39;00m\n\u001b[1;32m     27\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Set reduction='none' to get the loss per sample\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m loss_per_sample \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Initialize storage for metrics\u001b[39;00m\n\u001b[1;32m     31\u001b[0m precision_per_class \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/modules/loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# client-enhanced evaluation function\n",
    "def client_enhanced_evaluation(model, device, test_loader):\n",
    "    model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     for data, target in test_loader:\n",
    "    #         data, target = data.to(device), target.to(device)\n",
    "    #         output = model(data)\n",
    "    #         y_pred.extend(output.argmax(dim=1, keepdim=True).cpu().numpy())\n",
    "    #         y_true.extend(target.cpu().numpy())\n",
    "            \n",
    "    # Accumulate predictions and targets\n",
    "    y_pred, y_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            y_pred.append(output.argmax(dim=1).cpu())\n",
    "            y_true.append(target.cpu())\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    y_true = torch.cat(y_true)\n",
    "    y_pred = torch.cat(y_pred)\n",
    "\n",
    "    # Calculate the loss for each sample\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')  # Set reduction='none' to get the loss per sample\n",
    "    loss_per_sample = criterion(y_pred, y_true).cpu()\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    precision_per_class = []\n",
    "    recall_per_class = []\n",
    "    f1_per_class = []\n",
    "    accuracy_per_class = []\n",
    "    loss_per_class = []\n",
    "\n",
    "    # Iterate through each class (for MNIST, classes are 0 to 9)\n",
    "    for class_idx in range(model.num_classes):\n",
    "        # Get all predictions and ground truths for the current class\n",
    "        class_mask = (y_true == class_idx)  # Mask for this class\n",
    "        \n",
    "        y_true_class = (y_true == class_idx)  # Convert to binary for the current class\n",
    "        y_pred_class = (y_pred == class_idx)  # Convert to binary for the current class\n",
    "        \n",
    "        # Compute precision, recall, and F1-score for this class (treat as binary classification)\n",
    "        precision = precision_score(y_true_class, y_pred_class, average='binary', pos_label=1)\n",
    "        recall = recall_score(y_true_class, y_pred_class, average='binary', pos_label=1)\n",
    "        f1 = f1_score(y_true_class, y_pred_class, average='binary', pos_label=1)\n",
    "        accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "        \n",
    "        # Compute the loss for this class (average the loss of samples in this class)\n",
    "        class_loss = loss_per_sample[class_mask].mean().item() if class_mask.sum() > 0 else 0\n",
    "        \n",
    "        # Append metrics to the lists\n",
    "        precision_per_class.append(precision)\n",
    "        recall_per_class.append(recall)\n",
    "        f1_per_class.append(f1)\n",
    "        accuracy_per_class.append(accuracy)\n",
    "        loss_per_class.append(class_loss)\n",
    "        \n",
    "    return precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class\n",
    "\n",
    "# Evaluate the model\n",
    "precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class = client_enhanced_evaluation(model, device, test_loader)\n",
    "print(f\"Precision per class: {precision_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 84])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the last layer weights\n",
    "model.fc3.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet-9 (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.393180\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.125153\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.061068\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.140412\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.020400\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.041769\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.004259\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.029730\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.007122\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.084373\n",
      "\n",
      "Test set: Average loss: 0.0489, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.074853\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.016679\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.052707\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.055934\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.004753\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.023614\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.115123\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.003418\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.018911\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.004706\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.020622\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.004132\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000469\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.003857\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.019780\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.016303\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.004763\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.053840\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.085678\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.030130\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 9923/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001537\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.013710\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.006243\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.019015\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.004558\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.013583\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.002078\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.000520\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.009588\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.007469\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 9942/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001560\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000405\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000278\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.001224\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.038621\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.004806\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000261\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.001285\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.014120\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 9952/10000 (100%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001588\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000224\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000305\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.000154\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.000201\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.004838\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000901\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000097\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000648\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.000989\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 9956/10000 (100%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.001478\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.000111\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.001215\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.001083\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000181\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.000939\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000340\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.020601\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.000151\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.007565\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 9946/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000060\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000072\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000316\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.077998\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.001265\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.003571\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000080\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000818\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000254\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.004676\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 9943/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000207\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000062\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000029\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000058\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000203\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000093\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000224\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000728\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000062\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.001300\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 9941/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000113\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.000358\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.002204\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.000817\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.000080\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.000959\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000054\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.000070\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000045\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.002585\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 9913/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the conv_bn_relu_pool function\n",
    "def conv_bn_relu_pool(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    ]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.prep = conv_bn_relu_pool(in_channels, 64)\n",
    "        self.layer1_head = conv_bn_relu_pool(64, 128, pool=True)\n",
    "        self.layer1_residual = nn.Sequential(conv_bn_relu_pool(128, 128), conv_bn_relu_pool(128, 128))\n",
    "        self.layer2 = conv_bn_relu_pool(128, 256, pool=True)\n",
    "        self.layer3_head = conv_bn_relu_pool(256, 512, pool=True)\n",
    "        self.layer3_residual = nn.Sequential(conv_bn_relu_pool(512, 512), conv_bn_relu_pool(512, 512))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Changed to adaptive average pooling:         self.MaxPool2d = nn.Sequential(nn.MaxPool2d(4))\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        x = self.layer1_head(x)\n",
    "        x = self.layer1_residual(x) + x\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3_head(x)\n",
    "        x = self.layer3_residual(x) + x\n",
    "        x = self.avgpool(x)  # Changed to adaptive average pooling\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Define a function to train the model\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Define a function to test the model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "\n",
    "# Main function to run the training and testing\n",
    "def main():\n",
    "    # Training settings\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    no_cuda = False\n",
    "    seed = 1\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    model = ResNet9(in_channels=1, num_classes=10).to(device)  # Set in_channels to 1 for MNIST\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5 model has 61,706 parameters\n",
      "ResNet-9 model has 6,573,705 parameters\n"
     ]
    }
   ],
   "source": [
    "# model parameters\n",
    "model_lenet = LeNet5()\n",
    "print(f'LeNet-5 model has {sum(p.numel() for p in model_lenet.parameters()):,} parameters')\n",
    "model_resnet9 = ResNet9(in_channels=1, num_classes=9)\n",
    "print(f'ResNet-9 model has {sum(p.numel() for p in model_resnet9.parameters()):,} parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainings on ours dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m\n\u001b[1;32m     21\u001b[0m     clients_data \u001b[38;5;241m=\u001b[39m noniidgen\u001b[38;5;241m.\u001b[39msplit_feature_skew(\n\u001b[1;32m     22\u001b[0m         train_features \u001b[38;5;241m=\u001b[39m train_images,\n\u001b[1;32m     23\u001b[0m         train_labels \u001b[38;5;241m=\u001b[39m train_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m         random_order \u001b[38;5;241m=\u001b[39m random_order\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clients_data\n\u001b[0;32m---> 39\u001b[0m data_MNIST \u001b[38;5;241m=\u001b[39m \u001b[43mdata_creation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMNIST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m data_FMNIST \u001b[38;5;241m=\u001b[39m data_creation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFMNIST\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m data_CIFAR10 \u001b[38;5;241m=\u001b[39m data_creation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m, in \u001b[0;36mdata_creation\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m random_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Run split_feature_skew\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m clients_data \u001b[38;5;241m=\u001b[39m \u001b[43mnoniidgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_feature_skew\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_number\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclient_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mset_rotation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mset_rotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrotations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_rotation_low\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_rotation_low\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_rotation_high\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_rotation_high\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mset_color\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mset_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_color_low\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_color_low\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_color_high\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_color_high\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_order\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_order\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clients_data\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-USI/PC/Desktop/USI_Locale/CFL/non_iiddata_generator_no_drifting.py:483\u001b[0m, in \u001b[0;36msplit_feature_skew\u001b[0;34m(train_features, train_labels, test_features, test_labels, client_number, set_rotation, rotations, scaling_rotation_low, scaling_rotation_high, set_color, colors, scaling_color_low, scaling_color_high, random_order, show_distribution)\u001b[0m\n\u001b[1;32m    480\u001b[0m         train_rotations \u001b[38;5;241m=\u001b[39m total_rotations[:len_train]\n\u001b[1;32m    481\u001b[0m         test_rotations \u001b[38;5;241m=\u001b[39m total_rotations[len_train:]\n\u001b[0;32m--> 483\u001b[0m         client_data_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrotate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_data_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_rotations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m         client_data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m rotate_dataset(client_data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m], test_rotations)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_color:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-USI/PC/Desktop/USI_Locale/CFL/non_iiddata_generator_no_drifting.py:162\u001b[0m, in \u001b[0;36mrotate_dataset\u001b[0;34m(dataset, degrees)\u001b[0m\n\u001b[1;32m    159\u001b[0m     rotated_img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mrotate(degree)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Convert the PIL image back to a tensor\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     rotated_img_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrotated_img\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    164\u001b[0m     rotated_images\u001b[38;5;241m.\u001b[39mappend(rotated_img_tensor)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Stack all tensors into a single tensor\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torchvision/transforms/functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    167\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mbyteorder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlittle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16B\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m--> 168\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    171\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/PIL/Image.py:742\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/PIL/Image.py:808\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# unpack data\u001b[39;00m\n\u001b[0;32m--> 808\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43m_getencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m e\u001b[38;5;241m.\u001b[39msetimage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim)\n\u001b[1;32m    811\u001b[0m bufsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m65536\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m)  \u001b[38;5;66;03m# see RawEncode.c\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/PIL/Image.py:449\u001b[0m, in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder(mode, \u001b[38;5;241m*\u001b[39margs \u001b[38;5;241m+\u001b[39m extra)\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getencoder\u001b[39m(\n\u001b[1;32m    450\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m, encoder_name: \u001b[38;5;28mstr\u001b[39m, args: Any, extra: \u001b[38;5;28mtuple\u001b[39m[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m    451\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core\u001b[38;5;241m.\u001b[39mImagingEncoder \u001b[38;5;241m|\u001b[39m ImageFile\u001b[38;5;241m.\u001b[39mPyEncoder:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# tweak arguments\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         args \u001b[38;5;241m=\u001b[39m ()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import non_iiddata_generator_no_drifting as noniidgen\n",
    "\n",
    "def data_creation(dataset_name):\n",
    "    # Load the dataset\n",
    "    # Options: \"MNIST\", \"FMNIST\", \"CIFAR10\", \"CIFAR100\", etc.\n",
    "    train_images, train_labels, test_images, test_labels = noniidgen.load_full_datasets(dataset_name)\n",
    "\n",
    "    # Define parameters for split_feature_skew\n",
    "    client_number = 10\n",
    "    set_rotation = True\n",
    "    rotations = 4\n",
    "    scaling_rotation_low = 0.1\n",
    "    scaling_rotation_high = 0.2\n",
    "    set_color = True\n",
    "    colors = 3\n",
    "    scaling_color_low = 0.1\n",
    "    scaling_color_high = 0.2\n",
    "    random_order = True\n",
    "\n",
    "    # Run split_feature_skew\n",
    "    clients_data = noniidgen.split_feature_skew(\n",
    "        train_features = train_images,\n",
    "        train_labels = train_labels,\n",
    "        test_features = test_images,\n",
    "        test_labels = test_labels,\n",
    "        client_number = client_number,\n",
    "        set_rotation = set_rotation,\n",
    "        rotations = rotations,\n",
    "        scaling_rotation_low = scaling_rotation_low,\n",
    "        scaling_rotation_high = scaling_rotation_high,\n",
    "        set_color = set_color,\n",
    "        colors = colors,\n",
    "        scaling_color_low = scaling_color_low,\n",
    "        scaling_color_high = scaling_color_high,\n",
    "        random_order = random_order\n",
    "    )\n",
    "    return clients_data\n",
    "\n",
    "data_MNIST = data_creation(\"MNIST\")\n",
    "data_FMNIST = data_creation(\"FMNIST\")\n",
    "data_CIFAR10 = data_creation(\"CIFAR10\")\n",
    "data_CIFAR100 = data_creation(\"CIFAR100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.492195\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.239441\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.164107\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.944633\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.713479\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.004442\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.913772\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.762644\n",
      "\n",
      "Test set: Average loss: 1.7305, Accuracy: 3724/10000 (37%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.895573\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.940766\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.958923\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.622462\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.713544\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.967214\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.407248\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.528836\n",
      "\n",
      "Test set: Average loss: 1.6656, Accuracy: 4110/10000 (41%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.456856\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.339177\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.494506\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.454145\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.425265\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.579947\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.543551\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.415182\n",
      "\n",
      "Test set: Average loss: 1.3105, Accuracy: 5354/10000 (54%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.602923\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.366930\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.235944\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.298732\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.094521\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.063001\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.243723\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.839254\n",
      "\n",
      "Test set: Average loss: 1.3724, Accuracy: 5174/10000 (52%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.069730\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.102493\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.870357\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.016649\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.056112\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.993669\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.031552\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.192953\n",
      "\n",
      "Test set: Average loss: 1.1694, Accuracy: 5931/10000 (59%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.104963\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.062804\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.888746\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.868818\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.778530\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.829901\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.244481\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.305514\n",
      "\n",
      "Test set: Average loss: 1.1246, Accuracy: 6184/10000 (62%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.916303\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.939575\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.785785\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.640003\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.022498\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.894803\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.841459\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.588679\n",
      "\n",
      "Test set: Average loss: 1.0482, Accuracy: 6402/10000 (64%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.594068\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.634710\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.662204\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.488437\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.581229\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.622351\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.726629\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.768913\n",
      "\n",
      "Test set: Average loss: 1.0358, Accuracy: 6590/10000 (66%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.554226\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.646536\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.587347\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.523803\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.870944\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.717994\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.651073\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.620309\n",
      "\n",
      "Test set: Average loss: 1.1104, Accuracy: 6542/10000 (65%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.489968\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.509784\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.375537\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.410504\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.465466\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.478827\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.686940\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.423189\n",
      "\n",
      "Test set: Average loss: 1.1751, Accuracy: 6542/10000 (65%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import transforms\n",
    "from math import prod\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, features, labels, transform=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        y = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "def merge_data(data):\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "    for client_data in data:\n",
    "        train_features.append(client_data['train_features'])\n",
    "        train_labels.append(client_data['train_labels'])\n",
    "        test_features.append(client_data['test_features'])\n",
    "        test_labels.append(client_data['test_labels'])\n",
    "\n",
    "    # Concatenate all the data\n",
    "    train_features = torch.cat(train_features, dim=0)\n",
    "    train_labels = torch.cat(train_labels, dim=0)\n",
    "    test_features = torch.cat(test_features, dim=0)\n",
    "    test_labels = torch.cat(test_labels, dim=0)\n",
    "\n",
    "    return train_features, train_labels, test_features, test_labels\n",
    "    \n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10, input_size=(28, 28)):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "        # Calculate the size of the features after convolutional layers\n",
    "        dummy_input = torch.zeros(1, in_channels, *input_size)\n",
    "        dummy_output = self.pool2(self.conv2(self.pool1(self.conv1(dummy_input))))\n",
    "        self.feature_size = prod(dummy_output.size()[1:])\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.feature_size, 120)  # Fully connected layer, output size 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "        x = self.pool1(x)  # Apply subsampling pool1\n",
    "        x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "        x = self.pool2(x)  # Apply subsampling pool2\n",
    "        x = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU after fc1\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Define a function to train the model\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Define a function to test the model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "    \n",
    "# define device\n",
    "def check_gpu(manual_seed=True, print_info=True):\n",
    "    if manual_seed:\n",
    "        torch.manual_seed(0)\n",
    "    if torch.cuda.is_available():\n",
    "        if print_info:\n",
    "            print(\"CUDA is available\")\n",
    "        device = 'cuda'\n",
    "        torch.cuda.manual_seed_all(0) \n",
    "    elif torch.backends.mps.is_available():\n",
    "        if print_info:\n",
    "            print(\"MPS is available\")\n",
    "        device = torch.device(\"mps\")\n",
    "        torch.mps.manual_seed(0)\n",
    "    else:\n",
    "        if print_info:\n",
    "            print(\"CUDA is not available\")\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "# Main function to run the training and testing\n",
    "def main():\n",
    "    # Training settings\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    no_cuda = False\n",
    "    seed = 1\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # merge the data\n",
    "    train_features, train_labels, test_features, test_labels = merge_data(data_CIFAR10)\n",
    "\n",
    "    # Define any necessary transforms\n",
    "    transform = None\n",
    "\n",
    "    # Create the datasets\n",
    "    train_dataset = CombinedDataset(train_features, train_labels, transform=transform)\n",
    "    test_dataset = CombinedDataset(test_features, test_labels, transform=transform)\n",
    "\n",
    "    # Define batch sizes\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "\n",
    "    # Create the data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    # model = LeNet5(in_channels=3, num_classes=10, input_size=(32,32)).to(device)\n",
    "    model = ResNet9(in_channels=3, num_classes=10).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples with our models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.311269\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.299786\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.297932\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.296077\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.280352\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.140450\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.250665\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.247782\n",
      "\n",
      "Test set: Average loss: 2.1686, Accuracy: 2076/10000 (21%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.215068\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 2.160078\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.154256\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 2.040477\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 2.118145\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 2.168162\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 2.121017\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 2.161525\n",
      "\n",
      "Test set: Average loss: 2.0218, Accuracy: 2659/10000 (27%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.162241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m         simple_test(model, device, test_loader)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 72\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, momentum\u001b[38;5;241m=\u001b[39mmomentum)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m     \u001b[43msimple_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     simple_test(model, device, test_loader)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-USI/PC/Desktop/USI_Locale/cfl_maggio/models.py:135\u001b[0m, in \u001b[0;36msimple_train\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m    133\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    134\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m--> 135\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    137\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "import non_iiddata_generator_no_drifting as noniidgen\n",
    "from non_iiddata_generator_no_drifting import merge_data\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    model_name = \"LeNet5\"   # Options: \"LeNet5\", \"ResNet9\"\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    seed = 1\n",
    "    transform = None\n",
    "    # dataset settings\n",
    "    dataset_name = \"CIFAR10\"\n",
    "    client_number = 10\n",
    "    set_rotation = True\n",
    "    rotations = 4\n",
    "    scaling_rotation_low = 0.1\n",
    "    scaling_rotation_high = 0.2\n",
    "    set_color = True\n",
    "    colors = 3\n",
    "    scaling_color_low = 0.1\n",
    "    scaling_color_high = 0.2\n",
    "    random_order = True\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # load data \n",
    "    train_images, train_labels, test_images, test_labels = noniidgen.load_full_datasets(dataset_name)\n",
    "\n",
    "    # create data: split_feature_skew\n",
    "    clients_data = noniidgen.split_feature_skew(\n",
    "        train_features = train_images,\n",
    "        train_labels = train_labels,\n",
    "        test_features = test_images,\n",
    "        test_labels = test_labels,\n",
    "        client_number = client_number,\n",
    "        set_rotation = set_rotation,\n",
    "        rotations = rotations,\n",
    "        scaling_rotation_low = scaling_rotation_low,\n",
    "        scaling_rotation_high = scaling_rotation_high,\n",
    "        set_color = set_color,\n",
    "        colors = colors,\n",
    "        scaling_color_low = scaling_color_low,\n",
    "        scaling_color_high = scaling_color_high,\n",
    "        random_order = random_order\n",
    "    )\n",
    "\n",
    "    # merge the data (for Centralized Learning Simulation)\n",
    "    train_features, train_labels, test_features, test_labels = merge_data(clients_data)\n",
    "\n",
    "    # Create the datasets\n",
    "    train_dataset = CombinedDataset(train_features, train_labels, transform=transform)\n",
    "    test_dataset = CombinedDataset(test_features, test_labels, transform=transform)\n",
    "\n",
    "    # Create the data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    # model = LeNet5(in_channels=3, num_classes=10, input_size=(32,32)).to(device)\n",
    "    model = models[model_name](in_channels=3, num_classes=10, input_size=(32,32)).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        simple_train(model, device, train_loader, optimizer, epoch)\n",
    "        simple_test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5 model has 83,126 parameters\n",
      "ResNet-9 model has 6,590,730 parameters\n",
      "LeNet-5 model has 62,006 parameters\n",
      "ResNet-9 model has 6,575,370 parameters\n"
     ]
    }
   ],
   "source": [
    "# print the number of parameters\n",
    "model_lenet = LeNet5(in_channels=3, num_classes=10, input_size=(32,32))\n",
    "print(f'LeNet-5 model has {sum(p.numel() for p in model_lenet.parameters()):,} parameters')\n",
    "model_resnet9 = ResNet9(in_channels=3, num_classes=10, input_size=(32,32))\n",
    "print(f'ResNet-9 model has {sum(p.numel() for p in model_resnet9.parameters()):,} parameters')\n",
    "\n",
    "model_lenet = LeNet5(in_channels=3, num_classes=10, input_size=(28,28))\n",
    "print(f'LeNet-5 model has {sum(p.numel() for p in model_lenet.parameters()):,} parameters')\n",
    "model_resnet9 = ResNet9(in_channels=3, num_classes=10, input_size=(28,28))\n",
    "print(f'ResNet-9 model has {sum(p.numel() for p in model_resnet9.parameters()):,} parameters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 0 [0/5000 (0%)]\tLoss: 2.305545\n",
      "Train Epoch: 0 [640/5000 (13%)]\tLoss: 2.302148\n",
      "Train Epoch: 0 [1280/5000 (25%)]\tLoss: 2.309596\n",
      "Train Epoch: 0 [1920/5000 (38%)]\tLoss: 2.300848\n",
      "Train Epoch: 0 [2560/5000 (51%)]\tLoss: 2.302197\n",
      "Train Epoch: 0 [3200/5000 (63%)]\tLoss: 2.310703\n",
      "Train Epoch: 0 [3840/5000 (76%)]\tLoss: 2.304026\n",
      "Train Epoch: 0 [4480/5000 (89%)]\tLoss: 2.303044\n",
      "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.303247\n",
      "Train Epoch: 1 [640/5000 (13%)]\tLoss: 2.304303\n",
      "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.296026\n",
      "Train Epoch: 1 [1920/5000 (38%)]\tLoss: 2.301974\n",
      "Train Epoch: 1 [2560/5000 (51%)]\tLoss: 2.303057\n",
      "Train Epoch: 1 [3200/5000 (63%)]\tLoss: 2.295039\n",
      "Train Epoch: 1 [3840/5000 (76%)]\tLoss: 2.297525\n",
      "Train Epoch: 1 [4480/5000 (89%)]\tLoss: 2.304764\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import models    \n",
    "import config as cfg\n",
    "import numpy as np\n",
    "import utils\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# check gpu and set manual seed\n",
    "device = utils.check_gpu(manual_seed=True)\n",
    "\n",
    "# model and history folder\n",
    "model = models.models[cfg.model_name](in_channels=3, num_classes=cfg.n_classes, input_size=cfg.input_size).to(device)\n",
    "# train_fn = utils.trainings[args.model]\n",
    "# evaluate_fn = utils.evaluations[args.model]\n",
    "# plot_fn = utils.plot_functions[args.model]\n",
    "# config = utils.config_tests[args.dataset][args.model]\n",
    "\n",
    "# check if metrics.csv exists otherwise delete it\n",
    "# utils.check_and_delete_metrics_file(config['history_folder'] + f\"client_{args.data_type}_{args.id}\", question=False)\n",
    "\n",
    "# load data\n",
    "data = np.load(f'./data/client_{1}.npy', allow_pickle=True).item()\n",
    "num_examples = data['train_features'].shape[0]\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = models.CombinedDataset(data['train_features'], data['train_labels'], transform=None)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True)\n",
    "\n",
    "# Optimizer and Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=cfg.lr, momentum=cfg.momentum)\n",
    "\n",
    "\n",
    "for epoch in range(2):\n",
    "                models.simple_train(model, device, train_loader, optimizer, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def get_parameters(model, config):\n",
    "        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "def set_parameters(model, parameters):\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_parameters(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 20)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([\n",
    "    [3.65162887e-01, 4.56929939e-01, 4.35936778e-01, 6.09910640e-02,\n",
    "     1.85192110e-01, 7.50733292e-01, 0.00000000e+00, 9.99004801e-01,\n",
    "     8.12366388e-01, 4.31559287e-01, 1.99469020e-01, 0.00000000e+00,\n",
    "     8.52090274e-01, 6.06489022e-01, 3.05593218e-01, 1.63307399e-01,\n",
    "     9.90696194e-01, 1.20848937e-01, 4.27725571e-01, 4.62385859e-01],\n",
    "    \n",
    "    [3.58304323e-01, 4.58158605e-01, 4.20927672e-01, 5.93459187e-02,\n",
    "     2.30238225e-01, 7.49258300e-01, 1.44927106e-03, 9.64048185e-01,\n",
    "     8.28409274e-01, 4.35782453e-01, 1.81313614e-01, 3.65334775e-03,\n",
    "     8.46537114e-01, 6.04518982e-01, 3.16127594e-01, 1.61026342e-01,\n",
    "     1.00000000e+00, 1.26315181e-01, 4.24459401e-01, 4.62228778e-01],\n",
    "    \n",
    "    [3.58845450e-01, 4.69773548e-01, 4.36391839e-01, 6.36007412e-02,\n",
    "     1.83665676e-01, 7.49457142e-01, 2.99252216e-03, 1.00000000e+00,\n",
    "     8.15619086e-01, 4.36097039e-01, 1.98040994e-01, 2.75154805e-04,\n",
    "     8.52503664e-01, 6.05299061e-01, 3.04613466e-01, 1.62676152e-01,\n",
    "     9.90541617e-01, 1.20735128e-01, 4.28302844e-01, 4.62946838e-01]\n",
    "    \n",
    "])\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pca\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "y = pca.fit_transform(data)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kmean\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Transpose the data so that the clients (first dimension) become rows (3x20)\n",
    "transposed_data = data.T\n",
    "\n",
    "# Range of cluster numbers to try\n",
    "range_n_clusters = range(2, data.shape[0])  # Adjust based on your data size\n",
    "\n",
    "# Store inertia (sum of squared distances to centroids) and silhouette scores\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(transposed_data)\n",
    "    \n",
    "    # Append inertia (elbow method)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    \n",
    "    # Calculate silhouette score and append\n",
    "    silhouette_avg = silhouette_score(transposed_data, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CIAO'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ciao'.upper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CF_FL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
