{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5 (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "\n",
      "Test set: Average loss: 2.2608, Accuracy: 3158/10000 (32%)\n",
      "\n",
      "Latent Mean: 0.16155964136123657, Latent Std: 0.17962320148944855, Latent Max: 0.8367756605148315, Latent Min: 4.525206350081135e-06\n",
      "\n",
      "Test set: Average loss: 1.0852, Accuracy: 6539/10000 (65%)\n",
      "\n",
      "Latent Mean: 1.9909775257110596, Latent Std: 2.1955525875091553, Latent Max: 10.501509666442871, Latent Min: 8.462696996502928e-07\n",
      "\n",
      "Test set: Average loss: 0.6658, Accuracy: 7929/10000 (79%)\n",
      "\n",
      "Latent Mean: 2.3062903881073, Latent Std: 2.6182315349578857, Latent Max: 11.051698684692383, Latent Min: 1.6220154748225468e-06\n",
      "\n",
      "Test set: Average loss: 0.4149, Accuracy: 8673/10000 (87%)\n",
      "\n",
      "Latent Mean: 2.1366264820098877, Latent Std: 2.330186605453491, Latent Max: 10.01394271850586, Latent Min: 2.7257292458671145e-06\n",
      "\n",
      "Test set: Average loss: 0.3518, Accuracy: 8895/10000 (89%)\n",
      "\n",
      "Latent Mean: 2.2515532970428467, Latent Std: 2.424161672592163, Latent Max: 10.935249328613281, Latent Min: 4.064067525177961e-06\n",
      "\n",
      "Test set: Average loss: 0.4285, Accuracy: 8672/10000 (87%)\n",
      "\n",
      "Latent Mean: 1.8576445579528809, Latent Std: 1.9860944747924805, Latent Max: 10.421456336975098, Latent Min: 5.785029316029977e-06\n",
      "\n",
      "Test set: Average loss: 0.2604, Accuracy: 9158/10000 (92%)\n",
      "\n",
      "Latent Mean: 1.769097089767456, Latent Std: 1.8061304092407227, Latent Max: 8.861196517944336, Latent Min: 7.051219654385932e-06\n",
      "\n",
      "Test set: Average loss: 0.2462, Accuracy: 9263/10000 (93%)\n",
      "\n",
      "Latent Mean: 1.7997878789901733, Latent Std: 1.8471496105194092, Latent Max: 9.78065013885498, Latent Min: 7.904113772383425e-06\n",
      "\n",
      "Test set: Average loss: 0.2121, Accuracy: 9332/10000 (93%)\n",
      "\n",
      "Latent Mean: 1.7212644815444946, Latent Std: 1.7126710414886475, Latent Max: 9.434547424316406, Latent Min: 7.788448783685453e-06\n",
      "\n",
      "Test set: Average loss: 0.2335, Accuracy: 9284/10000 (93%)\n",
      "\n",
      "Latent Mean: 1.7396637201309204, Latent Std: 1.709773302078247, Latent Max: 9.525306701660156, Latent Min: 8.15233124740189e-06\n",
      "\n",
      "Test set: Average loss: 0.2135, Accuracy: 9338/10000 (93%)\n",
      "\n",
      "Latent Mean: 1.6251333951950073, Latent Std: 1.618355393409729, Latent Max: 9.087587356567383, Latent Min: 7.819674465281423e-06\n",
      "\n",
      "Test set: Average loss: 0.1724, Accuracy: 9445/10000 (94%)\n",
      "\n",
      "Latent Mean: 1.662046194076538, Latent Std: 1.6051448583602905, Latent Max: 9.165631294250488, Latent Min: 8.234178494603839e-06\n",
      "\n",
      "Test set: Average loss: 0.1661, Accuracy: 9507/10000 (95%)\n",
      "\n",
      "Latent Mean: 1.7718422412872314, Latent Std: 1.6853759288787842, Latent Max: 9.478252410888672, Latent Min: 8.093466931313742e-06\n",
      "\n",
      "Test set: Average loss: 0.1611, Accuracy: 9484/10000 (95%)\n",
      "\n",
      "Latent Mean: 1.800516963005066, Latent Std: 1.7077757120132446, Latent Max: 10.038788795471191, Latent Min: 7.934063432912808e-06\n",
      "\n",
      "Test set: Average loss: 0.2208, Accuracy: 9311/10000 (93%)\n",
      "\n",
      "Latent Mean: 1.8618983030319214, Latent Std: 1.7615978717803955, Latent Max: 10.30954360961914, Latent Min: 8.103173968265764e-06\n",
      "\n",
      "Test set: Average loss: 0.1657, Accuracy: 9517/10000 (95%)\n",
      "\n",
      "Latent Mean: 1.6178679466247559, Latent Std: 1.5396426916122437, Latent Max: 8.549905776977539, Latent Min: 8.44329406390898e-06\n",
      "\n",
      "Test set: Average loss: 0.1501, Accuracy: 9539/10000 (95%)\n",
      "\n",
      "Latent Mean: 1.6385855674743652, Latent Std: 1.5289884805679321, Latent Max: 9.102243423461914, Latent Min: 8.565641110180877e-06\n",
      "\n",
      "Test set: Average loss: 0.1466, Accuracy: 9548/10000 (95%)\n",
      "\n",
      "Latent Mean: 1.7622463703155518, Latent Std: 1.6375727653503418, Latent Max: 9.969928741455078, Latent Min: 8.789197636360768e-06\n",
      "\n",
      "Test set: Average loss: 0.1509, Accuracy: 9543/10000 (95%)\n",
      "\n",
      "Latent Mean: 1.813867211341858, Latent Std: 1.6889677047729492, Latent Max: 10.250991821289062, Latent Min: 8.91555282578338e-06\n",
      "\n",
      "Test set: Average loss: 0.1495, Accuracy: 9544/10000 (95%)\n",
      "\n",
      "Latent Mean: 1.860741138458252, Latent Std: 1.7172648906707764, Latent Max: 10.683937072753906, Latent Min: 8.92971638677409e-06\n",
      "\n",
      "Test set: Average loss: 0.1603, Accuracy: 9531/10000 (95%)\n",
      "\n",
      "Latent Mean: 1.7918285131454468, Latent Std: 1.6791255474090576, Latent Max: 10.280440330505371, Latent Min: 8.577561857237015e-06\n",
      "\n",
      "Test set: Average loss: 0.1929, Accuracy: 9450/10000 (94%)\n",
      "\n",
      "Latent Mean: 1.6792848110198975, Latent Std: 1.6274099349975586, Latent Max: 10.367240905761719, Latent Min: 8.672697731526569e-06\n",
      "\n",
      "Test set: Average loss: 0.1612, Accuracy: 9516/10000 (95%)\n",
      "\n",
      "Latent Mean: 1.5223419666290283, Latent Std: 1.4600852727890015, Latent Max: 9.562594413757324, Latent Min: 1.0025697520177346e-05\n",
      "\n",
      "Test set: Average loss: 0.1682, Accuracy: 9481/10000 (95%)\n",
      "\n",
      "Latent Mean: 1.67987060546875, Latent Std: 1.5333197116851807, Latent Max: 9.2020902633667, Latent Min: 1.319467537541641e-05\n",
      "\n",
      "Test set: Average loss: 0.1320, Accuracy: 9625/10000 (96%)\n",
      "\n",
      "Latent Mean: 1.7546513080596924, Latent Std: 1.621618390083313, Latent Max: 10.532086372375488, Latent Min: 1.238026288774563e-05\n",
      "\n",
      "Test set: Average loss: 0.1434, Accuracy: 9612/10000 (96%)\n",
      "\n",
      "Latent Mean: 1.8967795372009277, Latent Std: 1.7226500511169434, Latent Max: 10.653265953063965, Latent Min: 1.2516380593297072e-05\n",
      "\n",
      "Test set: Average loss: 0.1408, Accuracy: 9616/10000 (96%)\n",
      "\n",
      "Latent Mean: 1.9502230882644653, Latent Std: 1.767969012260437, Latent Max: 11.129339218139648, Latent Min: 1.2580571819853503e-05\n",
      "\n",
      "Test set: Average loss: 0.1481, Accuracy: 9607/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.039717674255371, Latent Std: 1.83516526222229, Latent Max: 11.373917579650879, Latent Min: 1.2572807463584468e-05\n",
      "\n",
      "Test set: Average loss: 0.1418, Accuracy: 9625/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.077848196029663, Latent Std: 1.8674285411834717, Latent Max: 11.654410362243652, Latent Min: 1.274099213333102e-05\n",
      "\n",
      "Test set: Average loss: 0.1451, Accuracy: 9631/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.1354401111602783, Latent Std: 1.9280319213867188, Latent Max: 12.087425231933594, Latent Min: 1.3316871445567813e-05\n",
      "\n",
      "Test set: Average loss: 0.1468, Accuracy: 9632/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.197566270828247, Latent Std: 1.978542447090149, Latent Max: 12.284961700439453, Latent Min: 1.357748988084495e-05\n",
      "\n",
      "Test set: Average loss: 0.1532, Accuracy: 9623/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.2372875213623047, Latent Std: 1.9954607486724854, Latent Max: 12.160377502441406, Latent Min: 1.3540637155529112e-05\n",
      "\n",
      "Test set: Average loss: 0.1547, Accuracy: 9633/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.2913894653320312, Latent Std: 2.0677475929260254, Latent Max: 12.952349662780762, Latent Min: 1.3520532775146421e-05\n",
      "\n",
      "Test set: Average loss: 0.1546, Accuracy: 9631/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.355790138244629, Latent Std: 2.0964670181274414, Latent Max: 12.901459693908691, Latent Min: 1.3092429981043097e-05\n",
      "\n",
      "Test set: Average loss: 0.1546, Accuracy: 9646/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.3932976722717285, Latent Std: 2.147242307662964, Latent Max: 13.25079345703125, Latent Min: 1.3501772627932951e-05\n",
      "\n",
      "Test set: Average loss: 0.1561, Accuracy: 9642/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.4397330284118652, Latent Std: 2.1854443550109863, Latent Max: 13.47666072845459, Latent Min: 1.3567126188718248e-05\n",
      "\n",
      "Test set: Average loss: 0.1757, Accuracy: 9594/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.4835562705993652, Latent Std: 2.2132725715637207, Latent Max: 13.577679634094238, Latent Min: 1.395200342813041e-05\n",
      "\n",
      "Test set: Average loss: 0.1628, Accuracy: 9653/10000 (97%)\n",
      "\n",
      "Latent Mean: 2.5158615112304688, Latent Std: 2.2553517818450928, Latent Max: 13.91468620300293, Latent Min: 1.4246866157918703e-05\n",
      "\n",
      "Test set: Average loss: 0.1693, Accuracy: 9628/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.5455334186553955, Latent Std: 2.2827630043029785, Latent Max: 14.039764404296875, Latent Min: 1.4295682376541663e-05\n",
      "\n",
      "Test set: Average loss: 0.1660, Accuracy: 9652/10000 (97%)\n",
      "\n",
      "Latent Mean: 2.580612897872925, Latent Std: 2.316661834716797, Latent Max: 14.151629447937012, Latent Min: 1.4449969057750423e-05\n",
      "\n",
      "Test set: Average loss: 0.1872, Accuracy: 9578/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.4656858444213867, Latent Std: 2.221663475036621, Latent Max: 13.661600112915039, Latent Min: 1.4617037777497899e-05\n",
      "\n",
      "Test set: Average loss: 0.1747, Accuracy: 9589/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.171066999435425, Latent Std: 2.001065254211426, Latent Max: 12.369756698608398, Latent Min: 1.4932289559510536e-05\n",
      "\n",
      "Test set: Average loss: 0.1599, Accuracy: 9603/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.1817307472229004, Latent Std: 1.9746955633163452, Latent Max: 11.879172325134277, Latent Min: 1.5242081644828431e-05\n",
      "\n",
      "Test set: Average loss: 0.1617, Accuracy: 9630/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.2774059772491455, Latent Std: 2.0621726512908936, Latent Max: 12.482172966003418, Latent Min: 1.5077921489137225e-05\n",
      "\n",
      "Test set: Average loss: 0.1612, Accuracy: 9643/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.354120969772339, Latent Std: 2.120042562484741, Latent Max: 12.88812255859375, Latent Min: 1.4906856449670158e-05\n",
      "\n",
      "Test set: Average loss: 0.1612, Accuracy: 9636/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.4059858322143555, Latent Std: 2.148942232131958, Latent Max: 13.076786994934082, Latent Min: 1.4884600204823073e-05\n",
      "\n",
      "Test set: Average loss: 0.1646, Accuracy: 9628/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.4505691528320312, Latent Std: 2.1837704181671143, Latent Max: 13.213899612426758, Latent Min: 1.4945708244340494e-05\n",
      "\n",
      "Test set: Average loss: 0.1692, Accuracy: 9653/10000 (97%)\n",
      "\n",
      "Latent Mean: 2.4942336082458496, Latent Std: 2.232459783554077, Latent Max: 13.520323753356934, Latent Min: 1.4829587598796934e-05\n",
      "\n",
      "Test set: Average loss: 0.1676, Accuracy: 9644/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.530378818511963, Latent Std: 2.259108066558838, Latent Max: 13.68305778503418, Latent Min: 1.4795270544709638e-05\n",
      "\n",
      "Test set: Average loss: 0.1690, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.5597734451293945, Latent Std: 2.286832571029663, Latent Max: 13.830415725708008, Latent Min: 1.4681952961836942e-05\n",
      "\n",
      "Test set: Average loss: 0.1758, Accuracy: 9643/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.5887908935546875, Latent Std: 2.3174729347229004, Latent Max: 14.014702796936035, Latent Min: 1.4674097656097729e-05\n",
      "\n",
      "Test set: Average loss: 0.1748, Accuracy: 9646/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.610959529876709, Latent Std: 2.3298702239990234, Latent Max: 14.04688549041748, Latent Min: 1.4767106222279835e-05\n",
      "\n",
      "Test set: Average loss: 0.1759, Accuracy: 9643/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.632357120513916, Latent Std: 2.346926689147949, Latent Max: 14.133345603942871, Latent Min: 1.46729544212576e-05\n",
      "\n",
      "Test set: Average loss: 0.1791, Accuracy: 9640/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.6607134342193604, Latent Std: 2.37614369392395, Latent Max: 14.342415809631348, Latent Min: 1.4516848750645295e-05\n",
      "\n",
      "Test set: Average loss: 0.1793, Accuracy: 9647/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.684169054031372, Latent Std: 2.393145799636841, Latent Max: 14.440129280090332, Latent Min: 1.4484472558251582e-05\n",
      "\n",
      "Test set: Average loss: 0.1817, Accuracy: 9642/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.7049753665924072, Latent Std: 2.411816358566284, Latent Max: 14.546147346496582, Latent Min: 1.4419359104067553e-05\n",
      "\n",
      "Test set: Average loss: 0.1841, Accuracy: 9646/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.7297210693359375, Latent Std: 2.431459903717041, Latent Max: 14.656010627746582, Latent Min: 1.4404873581952415e-05\n",
      "\n",
      "Test set: Average loss: 0.1847, Accuracy: 9641/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.739825963973999, Latent Std: 2.4382567405700684, Latent Max: 14.687952995300293, Latent Min: 1.4452480172622018e-05\n",
      "\n",
      "Test set: Average loss: 0.1868, Accuracy: 9642/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.756747245788574, Latent Std: 2.4558074474334717, Latent Max: 14.789055824279785, Latent Min: 1.4381424989551306e-05\n",
      "\n",
      "Test set: Average loss: 0.1877, Accuracy: 9640/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.778608798980713, Latent Std: 2.4731500148773193, Latent Max: 14.86441421508789, Latent Min: 1.4372699297382496e-05\n",
      "\n",
      "Test set: Average loss: 0.1890, Accuracy: 9644/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.7956786155700684, Latent Std: 2.486480951309204, Latent Max: 14.944022178649902, Latent Min: 1.4337223547045141e-05\n",
      "\n",
      "Test set: Average loss: 0.1905, Accuracy: 9651/10000 (97%)\n",
      "\n",
      "Latent Mean: 2.8094091415405273, Latent Std: 2.501460552215576, Latent Max: 15.016995429992676, Latent Min: 1.4329854820971377e-05\n",
      "\n",
      "Test set: Average loss: 0.1904, Accuracy: 9644/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.8257598876953125, Latent Std: 2.511373996734619, Latent Max: 15.087740898132324, Latent Min: 1.4289205864770338e-05\n",
      "\n",
      "Test set: Average loss: 0.1922, Accuracy: 9646/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.8397295475006104, Latent Std: 2.523524761199951, Latent Max: 15.145201683044434, Latent Min: 1.426137714588549e-05\n",
      "\n",
      "Test set: Average loss: 0.1942, Accuracy: 9639/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.853936195373535, Latent Std: 2.5409834384918213, Latent Max: 15.251402854919434, Latent Min: 1.4254337656893767e-05\n",
      "\n",
      "Test set: Average loss: 0.1952, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.868501663208008, Latent Std: 2.551565170288086, Latent Max: 15.303598403930664, Latent Min: 1.4228373402147554e-05\n",
      "\n",
      "Test set: Average loss: 0.1952, Accuracy: 9636/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.880406141281128, Latent Std: 2.5614423751831055, Latent Max: 15.3905029296875, Latent Min: 1.4202153579390142e-05\n",
      "\n",
      "Test set: Average loss: 0.1967, Accuracy: 9642/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.893968105316162, Latent Std: 2.572990655899048, Latent Max: 15.451882362365723, Latent Min: 1.4162702427711338e-05\n",
      "\n",
      "Test set: Average loss: 0.1967, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.905435562133789, Latent Std: 2.583284616470337, Latent Max: 15.514559745788574, Latent Min: 1.4187856322678272e-05\n",
      "\n",
      "Test set: Average loss: 0.1982, Accuracy: 9643/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.9193482398986816, Latent Std: 2.5944135189056396, Latent Max: 15.567193984985352, Latent Min: 1.4185519830789417e-05\n",
      "\n",
      "Test set: Average loss: 0.1991, Accuracy: 9641/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.930417776107788, Latent Std: 2.60589337348938, Latent Max: 15.637743949890137, Latent Min: 1.4161850231175777e-05\n",
      "\n",
      "Test set: Average loss: 0.2000, Accuracy: 9640/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.941554546356201, Latent Std: 2.614098310470581, Latent Max: 15.673501968383789, Latent Min: 1.415631140844198e-05\n",
      "\n",
      "Test set: Average loss: 0.2017, Accuracy: 9643/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.953305244445801, Latent Std: 2.6238062381744385, Latent Max: 15.723873138427734, Latent Min: 1.4134225239104126e-05\n",
      "\n",
      "Test set: Average loss: 0.2020, Accuracy: 9645/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.9633593559265137, Latent Std: 2.6330721378326416, Latent Max: 15.788113594055176, Latent Min: 1.4110073607298546e-05\n",
      "\n",
      "Test set: Average loss: 0.2026, Accuracy: 9643/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.974095344543457, Latent Std: 2.6430060863494873, Latent Max: 15.84924030303955, Latent Min: 1.4077395462663844e-05\n",
      "\n",
      "Test set: Average loss: 0.2035, Accuracy: 9638/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.983428716659546, Latent Std: 2.6522109508514404, Latent Max: 15.891504287719727, Latent Min: 1.407407398801297e-05\n",
      "\n",
      "Test set: Average loss: 0.2045, Accuracy: 9643/10000 (96%)\n",
      "\n",
      "Latent Mean: 2.9987096786499023, Latent Std: 2.663924217224121, Latent Max: 15.974533081054688, Latent Min: 1.400183464284055e-05\n",
      "\n",
      "Test set: Average loss: 0.2048, Accuracy: 9641/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.007744550704956, Latent Std: 2.671747922897339, Latent Max: 16.024572372436523, Latent Min: 1.3971229236631189e-05\n",
      "\n",
      "Test set: Average loss: 0.2062, Accuracy: 9638/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.0181262493133545, Latent Std: 2.6818461418151855, Latent Max: 16.079469680786133, Latent Min: 1.3962553566670977e-05\n",
      "\n",
      "Test set: Average loss: 0.2077, Accuracy: 9642/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.027287006378174, Latent Std: 2.6876847743988037, Latent Max: 16.09930419921875, Latent Min: 1.3931939065514598e-05\n",
      "\n",
      "Test set: Average loss: 0.2069, Accuracy: 9641/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.0355379581451416, Latent Std: 2.6961429119110107, Latent Max: 16.156410217285156, Latent Min: 1.3933798982179724e-05\n",
      "\n",
      "Test set: Average loss: 0.2084, Accuracy: 9641/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.0440070629119873, Latent Std: 2.703831911087036, Latent Max: 16.194211959838867, Latent Min: 1.3937917174189351e-05\n",
      "\n",
      "Test set: Average loss: 0.2088, Accuracy: 9640/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.0518486499786377, Latent Std: 2.7108936309814453, Latent Max: 16.233205795288086, Latent Min: 1.3915710042056162e-05\n",
      "\n",
      "Test set: Average loss: 0.2095, Accuracy: 9636/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.0606133937835693, Latent Std: 2.7179086208343506, Latent Max: 16.25759506225586, Latent Min: 1.3908086657465901e-05\n",
      "\n",
      "Test set: Average loss: 0.2100, Accuracy: 9640/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.0685784816741943, Latent Std: 2.723501205444336, Latent Max: 16.301097869873047, Latent Min: 1.3888381545257289e-05\n",
      "\n",
      "Test set: Average loss: 0.2114, Accuracy: 9637/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.076387643814087, Latent Std: 2.7321465015411377, Latent Max: 16.345300674438477, Latent Min: 1.387845532008214e-05\n",
      "\n",
      "Test set: Average loss: 0.2117, Accuracy: 9639/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.084716796875, Latent Std: 2.7378625869750977, Latent Max: 16.376882553100586, Latent Min: 1.3861170373274945e-05\n",
      "\n",
      "Test set: Average loss: 0.2125, Accuracy: 9638/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.093480110168457, Latent Std: 2.745863914489746, Latent Max: 16.41852378845215, Latent Min: 1.385076939186547e-05\n",
      "\n",
      "Test set: Average loss: 0.2134, Accuracy: 9638/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.101189374923706, Latent Std: 2.7530133724212646, Latent Max: 16.451332092285156, Latent Min: 1.3843208762409631e-05\n",
      "\n",
      "Test set: Average loss: 0.2135, Accuracy: 9638/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.107316255569458, Latent Std: 2.7580199241638184, Latent Max: 16.47868537902832, Latent Min: 1.3810647942591459e-05\n",
      "\n",
      "Test set: Average loss: 0.2143, Accuracy: 9638/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.114764451980591, Latent Std: 2.765148401260376, Latent Max: 16.524267196655273, Latent Min: 1.3813782061333768e-05\n",
      "\n",
      "Test set: Average loss: 0.2145, Accuracy: 9637/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.1215991973876953, Latent Std: 2.7706680297851562, Latent Max: 16.553211212158203, Latent Min: 1.3805372873321176e-05\n",
      "\n",
      "Test set: Average loss: 0.2148, Accuracy: 9641/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.1224334239959717, Latent Std: 2.771038293838501, Latent Max: 16.515737533569336, Latent Min: 1.3873812349629588e-05\n",
      "\n",
      "Test set: Average loss: 0.2160, Accuracy: 9635/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.1315135955810547, Latent Std: 2.7807536125183105, Latent Max: 16.593929290771484, Latent Min: 1.3864535503671505e-05\n",
      "\n",
      "Test set: Average loss: 0.2162, Accuracy: 9634/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.1383743286132812, Latent Std: 2.7861809730529785, Latent Max: 16.63682746887207, Latent Min: 1.384665029036114e-05\n",
      "\n",
      "Test set: Average loss: 0.2168, Accuracy: 9637/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.145745038986206, Latent Std: 2.791442632675171, Latent Max: 16.665674209594727, Latent Min: 1.3834430319548119e-05\n",
      "\n",
      "Test set: Average loss: 0.2172, Accuracy: 9641/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.152195692062378, Latent Std: 2.7969603538513184, Latent Max: 16.699378967285156, Latent Min: 1.3835163372277748e-05\n",
      "\n",
      "Test set: Average loss: 0.2182, Accuracy: 9637/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.158616542816162, Latent Std: 2.804441213607788, Latent Max: 16.75063705444336, Latent Min: 1.3829318049829453e-05\n",
      "\n",
      "Test set: Average loss: 0.2188, Accuracy: 9635/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.1686694622039795, Latent Std: 2.8108179569244385, Latent Max: 16.77820587158203, Latent Min: 1.38219547807239e-05\n",
      "\n",
      "Test set: Average loss: 0.2190, Accuracy: 9641/10000 (96%)\n",
      "\n",
      "Latent Mean: 3.1730010509490967, Latent Std: 2.8159537315368652, Latent Max: 16.806499481201172, Latent Min: 1.3820203093928285e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Define the LeNet-5 architecture\n",
    "# class LeNet5(nn.Module):\n",
    "#     def __init__(self, in_channels=1, num_classes=10):\n",
    "#         super(LeNet5, self).__init__()\n",
    "#         self.num_classes = num_classes\n",
    "#         self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "#         self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "#         self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "#         self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "#         # These layers depend on the input size\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Fully connected layer, output size 120\n",
    "#         self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "#         self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "#         x = self.pool1(x)  # Apply subsampling pool1\n",
    "#         x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "#         x = self.pool2(x)  # Apply subsampling pool2\n",
    "#         x = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "#         x = F.relu(self.fc1(x))  # Apply ReLU after fc1\n",
    "#         x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "#         x = self.fc3(x)  # Output layer\n",
    "#         return x\n",
    "\n",
    "# Define a function to train the model\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if batch_idx % 100 == 0:\n",
    "        #     print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "        #           f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Define a function to test the model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    latent_all = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, latent = model(data, latent=True)\n",
    "            latent_all.append(latent.cpu().numpy())\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "    \n",
    "    latent_all = np.concatenate(latent_all, axis=0)\n",
    "    latent_mean = np.mean(latent_all, axis=0)\n",
    "    print(f\"Latent Mean: {np.mean(latent_mean)}, Latent Std: {np.std(latent_mean)}, Latent Max: {np.max(latent_mean)}, Latent Min: {np.min(latent_mean)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "# define device\n",
    "def check_gpu(manual_seed=True, print_info=True):\n",
    "    if manual_seed:\n",
    "        torch.manual_seed(0)\n",
    "    if torch.cuda.is_available():\n",
    "        if print_info:\n",
    "            print(\"CUDA is available\")\n",
    "        device = 'cuda'\n",
    "        torch.cuda.manual_seed_all(0) \n",
    "    elif torch.backends.mps.is_available():\n",
    "        if print_info:\n",
    "            print(\"MPS is available\")\n",
    "        device = torch.device(\"mps\")\n",
    "        torch.mps.manual_seed(0)\n",
    "    else:\n",
    "        if print_info:\n",
    "            print(\"CUDA is not available\")\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "# Main function to run the training and testing\n",
    "def main():\n",
    "    # Training settings\n",
    "    batch_size = 128\n",
    "    test_batch_size = 1000\n",
    "    epochs = 100\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    no_cuda = False\n",
    "    seed = 1\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    # reduce the dimension of training data\n",
    "    train_dataset.data = train_dataset.data[:5000]\n",
    "    test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    model = LeNet5(in_channels=1, num_classes=10).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.679701\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.201030\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.127681\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.216661\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.090390\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.055544\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.012787\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.052081\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.006014\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.052296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    " \n",
    "# Training settings\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "epochs = 1\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "no_cuda = False\n",
    "seed = 1\n",
    "\n",
    "device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "# Define the LeNet-5 architecture\n",
    "# LeNet-5 model\n",
    "from math import prod\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10, input_size=(28, 28)):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "        # Dinamically calculate the size of the features after convolutional layers\n",
    "        dummy_input = torch.zeros(1, in_channels, *input_size)\n",
    "        dummy_output = self.pool2(self.conv2(self.pool1(self.conv1(dummy_input))))\n",
    "        self.feature_size = prod(dummy_output.size()[1:])\n",
    "\n",
    "        self.fc1 = nn.Linear(self.feature_size, 120)  # Fully connected layer, output size 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "    def forward(self, x, latent=False):\n",
    "        x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "        x = self.pool1(x)  # Apply subsampling pool1\n",
    "        x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "        x = self.pool2(x)  # Apply subsampling pool2\n",
    "        x_l = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "        x = F.relu(self.fc1(x_l))  # Apply ReLU after fc1\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        if latent:\n",
    "            return x, x_l\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "# LeNet-5 model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10, input_size=(28, 28)):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "        # Dinamically calculate the size of the features after convolutional layers\n",
    "        dummy_input = torch.zeros(1, in_channels, *input_size)\n",
    "        dummy_output = self.pool2(self.conv2(self.pool1(self.conv1(dummy_input))))\n",
    "        self.feature_size = prod(dummy_output.size()[1:])\n",
    "\n",
    "        self.fc1 = nn.Linear(self.feature_size, 120)  # Fully connected layer, output size 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "    def forward(self, x, latent=False):\n",
    "        x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "        x = self.pool1(x)  # Apply subsampling pool1\n",
    "        x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "        x = self.pool2(x)  # Apply subsampling pool2\n",
    "        x_l = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "        x = F.relu(self.fc1(x_l))  # Apply ReLU after fc1\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        if latent:\n",
    "            return x, x_l\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "\n",
    "# Resnet-9 layer\n",
    "def residual_block(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    ]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# ResNet-9 model\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, input_size=(28, 28)):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.prep = residual_block(in_channels, 64)\n",
    "        self.layer1_head = residual_block(64, 128, pool=True)\n",
    "        self.layer1_residual = nn.Sequential(residual_block(128, 128), residual_block(128, 128))\n",
    "        self.layer2 = residual_block(128, 256, pool=True)\n",
    "        self.layer3_head = residual_block(256, 512, pool=True)\n",
    "        self.layer3_residual = nn.Sequential(residual_block(512, 512), residual_block(512, 512))\n",
    "        # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Changed to adaptive average pooling:         self.MaxPool2d = nn.Sequential(nn.MaxPool2d(4))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Calculate the size of the features after the convolutional layers\n",
    "        dummy_input = torch.zeros(1, in_channels, *input_size)\n",
    "        dummy_output = self.pool(self.layer3_head(self.layer2(self.layer1_head(self.prep(dummy_input)))))\n",
    "        self.feature_size = dummy_output.size(1) * dummy_output.size(2) * dummy_output.size(3)\n",
    "\n",
    "        # Output layer\n",
    "        self.linear = nn.Linear(self.feature_size, num_classes)\n",
    "\n",
    "    def forward(self, x, latent=False):\n",
    "        x = self.prep(x)\n",
    "        x = self.layer1_head(x)\n",
    "        x = self.layer1_residual(x) + x\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3_head(x)\n",
    "        x = self.layer3_residual(x) + x\n",
    "        x = self.pool(x)  # Changed to adaptive average pooling\n",
    "        x_l = x.view(x.size(0), -1)\n",
    "        x = self.linear(x_l)\n",
    "        if latent:\n",
    "            return x, x_l\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "\n",
    "model = ResNet9(in_channels=1, num_classes=10).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ModelEvaluator class\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, test_loader, device):\n",
    "        \"\"\"\n",
    "        Initializes the ModelEvaluator with the model, device, and number of classes.\n",
    "        \n",
    "        Args:\n",
    "            test_loader: DataLoader with test data\n",
    "            device: Device to run the evaluation on\n",
    "        \"\"\"\n",
    "        \n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        self.criterion_trad = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Fit the PCA model \n",
    "        \n",
    "\n",
    "    def evaluate(self, model, latent=False):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the provided test data and returns various metrics.\n",
    "\n",
    "        Args:\n",
    "            model: Model to evaluate\n",
    "            latent: Whether to return the latent representation of the test data\n",
    "        \"\"\"\n",
    "        \n",
    "        # client-enhanced evaluation function\n",
    "        # def evaluate_model_per_class(model, device, test_loader, latent=False):\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        num_classes = model.num_classes\n",
    "\n",
    "        # Initialize storage for metrics\n",
    "        precision_per_class = [0] * num_classes\n",
    "        recall_per_class = [0] * num_classes\n",
    "        f1_per_class = [0] * num_classes\n",
    "        accuracy_per_class = [0] * num_classes\n",
    "        loss_per_class = [0] * num_classes\n",
    "        class_counts = [0] * num_classes\n",
    "\n",
    "        y_true_all = []\n",
    "        y_pred_all = []\n",
    "        loss_all = []\n",
    "        latent_all = []\n",
    "        loss_trad = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Accumulate predictions and targets over batches\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                \n",
    "                # Get model predictions\n",
    "                if latent: \n",
    "                    output, latent_space = model(data, latent=True)\n",
    "                    latent_all.extend(latent_space.cpu().numpy())\n",
    "                else: \n",
    "                    output = model(data) \n",
    "                    \n",
    "                y_pred_batch = output.argmax(dim=1, keepdim=False)  # Predicted class labels\n",
    "                \n",
    "                # Store the true and predicted labels for the batch\n",
    "                y_true_all.extend(target.cpu().numpy())\n",
    "                y_pred_all.extend(y_pred_batch.cpu().numpy())\n",
    "                \n",
    "                # Compute per-sample loss for the batch\n",
    "                batch_loss = self.criterion(output, target).cpu().numpy()\n",
    "                loss_all.extend(batch_loss)\n",
    "                \n",
    "                # Compute traditional loss for the batch\n",
    "                loss_trad += self.criterion_trad(output, target).item()\n",
    "                \n",
    "                # Accumulate the total number of samples\n",
    "                total_samples += len(target)\n",
    "\n",
    "        # Convert collected predictions and true labels into tensors for processing\n",
    "        y_true_all = torch.tensor(y_true_all)\n",
    "        y_pred_all = torch.tensor(y_pred_all)\n",
    "        loss_all = torch.tensor(loss_all)\n",
    "        \n",
    "        # Average traditional loss over the total number of samples\n",
    "        loss_trad /= total_samples\n",
    "        \n",
    "        # Calculate traditional accuracy on the entire test set\n",
    "        accuracy_trad = accuracy_score(y_true_all, y_pred_all)\n",
    "        \n",
    "        # Average latent\n",
    "        if latent:\n",
    "            latent_all = torch.tensor(latent_all)\n",
    "            latent_all = latent_all.view(latent_all.size(0), -1)\n",
    "            latent_all = latent_all.mean(dim=0).numpy()\n",
    "\n",
    "        # Iterate through each class (for MNIST, classes are 0 to 9 by default)\n",
    "        for class_idx in range(num_classes):\n",
    "            # Get all predictions and ground truths for the current class\n",
    "            class_mask = (y_true_all == class_idx)  # Mask for this class\n",
    "            \n",
    "            y_true_class = (y_true_all == class_idx).numpy().astype(int)  # Binary labels for the current class\n",
    "            y_pred_class = (y_pred_all == class_idx).numpy().astype(int)  # Binary predictions for the current class\n",
    "            \n",
    "            # Only calculate if there are samples for this class\n",
    "            if class_mask.sum() > 0:\n",
    "                # Compute precision, recall, and F1-score for this class\n",
    "                precision = precision_score(y_true_class, y_pred_class, zero_division=0)\n",
    "                recall = recall_score(y_true_class, y_pred_class, zero_division=0)\n",
    "                f1 = f1_score(y_true_class, y_pred_class, zero_division=0)\n",
    "                accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "\n",
    "                # Compute the loss for this class (average the loss of samples in this class)\n",
    "                class_loss = loss_all[class_mask].mean().item()\n",
    "\n",
    "                # Update class counts and metrics\n",
    "                precision_per_class[class_idx] = precision\n",
    "                recall_per_class[class_idx] = recall\n",
    "                f1_per_class[class_idx] = f1\n",
    "                accuracy_per_class[class_idx] = accuracy\n",
    "                loss_per_class[class_idx] = class_loss\n",
    "                class_counts[class_idx] = class_mask.sum().item()\n",
    "\n",
    "        return loss_trad, accuracy_trad, precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class, latent_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Loss: 4.95510027743876e-05, Traditional Accuracy: 0.9848\n",
      "Precision: [0.9918533604887984, 0.9964726631393298, 0.9940711462450593, 0.9776264591439688, 0.9957850368809273, 0.9746136865342163, 0.9968051118210862, 0.9551820728291317, 0.997907949790795, 0.9696969696969697]\n",
      "Recall: [0.9938775510204082, 0.9955947136563876, 0.9748062015503876, 0.995049504950495, 0.9623217922606925, 0.9899103139013453, 0.9770354906054279, 0.995136186770428, 0.9794661190965093, 0.9831516352824579]\n",
      "F1: [0.9928644240570846, 0.996033494931688, 0.9843444227005871, 0.9862610402355251, 0.9787674779906784, 0.982202447163515, 0.9868212967843965, 0.9747498808956646, 0.9886010362694301, 0.9763779527559056]\n",
      "Accuracy: [0.9986, 0.9991, 0.9968, 0.9972, 0.9959, 0.9968, 0.9975, 0.9947, 0.9978, 0.9952]\n",
      "Loss: [0.02462760917842388, 0.01422794908285141, 0.07511214166879654, 0.009373032487928867, 0.1041930541396141, 0.04359889402985573, 0.08723290264606476, 0.013723541982471943, 0.08038651198148727, 0.050607096403837204]\n",
      "Latent Mean: 0.8250105977058411, Latent Std: 0.6231111884117126, Latent Max: 4.5506157875061035, Latent Min: 0.0384863056242466\n"
     ]
    }
   ],
   "source": [
    "evaluator = ModelEvaluator(test_loader, device)\n",
    "loss_trad, accuracy_trad, precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class, latent_all = evaluator.evaluate(model, latent=True)\n",
    "print(f\"Traditional Loss: {loss_trad}, Traditional Accuracy: {accuracy_trad}\")\n",
    "print(f\"Precision: {precision_per_class}\")\n",
    "print(f\"Recall: {recall_per_class}\")\n",
    "print(f\"F1: {f1_per_class}\")\n",
    "print(f\"Accuracy: {accuracy_per_class}\")\n",
    "print(f\"Loss: {loss_per_class}\")\n",
    "print(f\"Latent Mean: {np.mean(latent_all)}, Latent Std: {np.std(latent_all)}, Latent Max: {np.max(latent_all)}, Latent Min: {np.min(latent_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.9918533604887984, 0.9964726631393298, 0.9940711462450593, 0.9776264591439688, 0.9957850368809273, 0.9746136865342163, 0.9968051118210862, 0.9551820728291317, 0.997907949790795, 0.9696969696969697]'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(precision_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # standard scaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    num_classes = model.num_classes\n",
    "    latent = True\n",
    "\n",
    "    # Define the cross-entropy loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    criterion_trad = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    precision_per_class = [0] * num_classes\n",
    "    recall_per_class = [0] * num_classes\n",
    "    f1_per_class = [0] * num_classes\n",
    "    accuracy_per_class = [0] * num_classes\n",
    "    loss_per_class = [0] * num_classes\n",
    "    class_counts = [0] * num_classes\n",
    "\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    loss_all = []\n",
    "    latent_all = []\n",
    "    loss_trad = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Accumulate predictions and targets over batches\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get model predictions\n",
    "            if latent: \n",
    "                output, latent_space = model(data, latent=True)\n",
    "                latent_all.extend(latent_space.cpu().numpy())\n",
    "            else: \n",
    "                output = model(data) \n",
    "                \n",
    "            y_pred_batch = output.argmax(dim=1, keepdim=False)  # Predicted class labels\n",
    "            \n",
    "            # Store the true and predicted labels for the batch\n",
    "            y_true_all.extend(target.cpu().numpy())\n",
    "            y_pred_all.extend(y_pred_batch.cpu().numpy())\n",
    "            \n",
    "            # Compute per-sample loss for the batch\n",
    "            batch_loss = criterion(output, target).cpu().numpy()\n",
    "            loss_all.extend(batch_loss)\n",
    "            \n",
    "            # Compute traditional loss for the batch\n",
    "            loss_trad += criterion_trad(output, target).item()\n",
    "            \n",
    "            # Accumulate the total number of samples\n",
    "            total_samples += len(target)\n",
    "\n",
    "    # Convert collected predictions and true labels into tensors for processing\n",
    "    y_true_all = torch.tensor(y_true_all)\n",
    "    y_pred_all = torch.tensor(y_pred_all)\n",
    "    loss_all = torch.tensor(loss_all)\n",
    "    \n",
    "    # Average traditional loss over the total number of samples\n",
    "    loss_trad /= total_samples\n",
    "    \n",
    "    # Calculate traditional accuracy on the entire test set\n",
    "    accuracy_trad = accuracy_score(y_true_all, y_pred_all)\n",
    "    \n",
    "    # normalize latent space\n",
    "    latent_all = np.array(latent_all)\n",
    "    latent_all = latent_all.mean(axis=0)\n",
    "    scaler.fit(latent_all.reshape(-1, 1))\n",
    "    latent_all = scaler.transform(latent_all.reshape(-1, 1))\n",
    "    \n",
    "    # PCA\n",
    "    rand_points = torch.normal(mean=0, std=1, size=(100, latent_all.shape[1]))\n",
    "    pca_model = PCA(n_components=30)\n",
    "    \n",
    "    # # Average latent\n",
    "    # if latent:\n",
    "    #     latent_all = torch.tensor(latent_all)\n",
    "    #     latent_all = latent_all.view(latent_all.size(0), -1)\n",
    "    #     latent_all = latent_all.mean(dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        rand_points = torch.normal(mean=0, std=0.1, size=(100, errors.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.9790297], dtype=float32),\n",
       " array([-1.2622539], dtype=float32),\n",
       " 0.99999994,\n",
       " -1.8626451e-09)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# latent_all = np.array(latent_all)\n",
    "# average latent space along the samples\n",
    "# latent_all_mean = latent_all.mean(axis=0)\n",
    "max(latent_all), min(latent_all), np.std(latent_all), np.mean(latent_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-wise evaluation:\n",
      "Class 0: Precision = 0.9797, Recall = 0.9837, F1 = 0.9817, Accuracy = 0.9964, Loss = 0.0577\n",
      "Class 1: Precision = 0.9868, Recall = 0.9877, F1 = 0.9872, Accuracy = 0.9971, Loss = 0.0401\n",
      "Class 2: Precision = 0.9488, Recall = 0.9874, F1 = 0.9677, Accuracy = 0.9932, Loss = 0.0427\n",
      "Class 3: Precision = 0.9446, Recall = 0.9792, F1 = 0.9616, Accuracy = 0.9921, Loss = 0.0633\n",
      "Class 4: Precision = 0.9747, Recall = 0.9827, F1 = 0.9787, Accuracy = 0.9958, Loss = 0.0559\n",
      "Class 5: Precision = 0.9593, Recall = 0.9776, F1 = 0.9684, Accuracy = 0.9943, Loss = 0.0750\n",
      "Class 6: Precision = 0.9874, Recall = 0.9781, F1 = 0.9827, Accuracy = 0.9967, Loss = 0.0676\n",
      "Class 7: Precision = 0.9792, Recall = 0.9601, F1 = 0.9695, Accuracy = 0.9938, Loss = 0.1321\n",
      "Class 8: Precision = 0.9788, Recall = 0.9476, F1 = 0.9630, Accuracy = 0.9929, Loss = 0.1553\n",
      "Class 9: Precision = 0.9865, Recall = 0.9386, F1 = 0.9619, Accuracy = 0.9925, Loss = 0.1915\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def evaluate_model_per_class(model, device, test_loader, num_classes=10):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Define the cross-entropy loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    precision_per_class = [0] * num_classes\n",
    "    recall_per_class = [0] * num_classes\n",
    "    f1_per_class = [0] * num_classes\n",
    "    accuracy_per_class = [0] * num_classes\n",
    "    loss_per_class = [0] * num_classes\n",
    "    class_counts = [0] * num_classes\n",
    "\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    loss_all = []\n",
    "\n",
    "    # Accumulate predictions and targets over batches\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get model predictions\n",
    "            output = model(data)\n",
    "            y_pred_batch = output.argmax(dim=1, keepdim=False)  # Predicted class labels\n",
    "            \n",
    "            # Store the true and predicted labels for the batch\n",
    "            y_true_all.extend(target.cpu().numpy())\n",
    "            y_pred_all.extend(y_pred_batch.cpu().numpy())\n",
    "            \n",
    "            # Compute per-sample loss for the batch\n",
    "            batch_loss = criterion(output, target).cpu().numpy()\n",
    "            loss_all.extend(batch_loss)\n",
    "\n",
    "    # Convert collected predictions and true labels into tensors for processing\n",
    "    y_true_all = torch.tensor(y_true_all)\n",
    "    y_pred_all = torch.tensor(y_pred_all)\n",
    "    loss_all = torch.tensor(loss_all)\n",
    "\n",
    "    # Iterate through each class (for MNIST, classes are 0 to 9 by default)\n",
    "    for class_idx in range(num_classes):\n",
    "        # Get all predictions and ground truths for the current class\n",
    "        class_mask = (y_true_all == class_idx)  # Mask for this class\n",
    "        \n",
    "        y_true_class = (y_true_all == class_idx).numpy().astype(int)  # Binary labels for the current class\n",
    "        y_pred_class = (y_pred_all == class_idx).numpy().astype(int)  # Binary predictions for the current class\n",
    "        \n",
    "        # Only calculate if there are samples for this class\n",
    "        if class_mask.sum() > 0:\n",
    "            # Compute precision, recall, and F1-score for this class\n",
    "            precision = precision_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            recall = recall_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            f1 = f1_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "\n",
    "            # Compute the loss for this class (average the loss of samples in this class)\n",
    "            class_loss = loss_all[class_mask].mean().item()\n",
    "\n",
    "            # Update class counts and metrics\n",
    "            precision_per_class[class_idx] = precision\n",
    "            recall_per_class[class_idx] = recall\n",
    "            f1_per_class[class_idx] = f1\n",
    "            accuracy_per_class[class_idx] = accuracy\n",
    "            loss_per_class[class_idx] = class_loss\n",
    "            class_counts[class_idx] = class_mask.sum().item()\n",
    "\n",
    "    return precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class\n",
    "\n",
    "precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class, loss_all = evaluate_model_per_class(model, device, test_loader)\n",
    "print(\"Class-wise evaluation:\")\n",
    "for class_idx in range(10):\n",
    "    print(f\"Class {class_idx}: Precision = {precision_per_class[class_idx]:.4f}, Recall = {recall_per_class[class_idx]:.4f}, F1 = {f1_per_class[class_idx]:.4f}, Accuracy = {accuracy_per_class[class_idx]:.4f}, Loss = {loss_per_class[class_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1629e-03, 1.5663e-04, 5.1977e-03,  ..., 7.3909e-06, 3.2062e-04,\n",
       "        8.0701e-05])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class \u001b[38;5;241m=\u001b[39m \u001b[43mclient_enhanced_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision per class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision_per_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 28\u001b[0m, in \u001b[0;36mclient_enhanced_evaluation\u001b[0;34m(model, device, test_loader)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate the loss for each sample\u001b[39;00m\n\u001b[1;32m     27\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Set reduction='none' to get the loss per sample\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m loss_per_sample \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Initialize storage for metrics\u001b[39;00m\n\u001b[1;32m     31\u001b[0m precision_per_class \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/modules/loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# client-enhanced evaluation function\n",
    "def client_enhanced_evaluation(model, device, test_loader):\n",
    "    model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     for data, target in test_loader:\n",
    "    #         data, target = data.to(device), target.to(device)\n",
    "    #         output = model(data)\n",
    "    #         y_pred.extend(output.argmax(dim=1, keepdim=True).cpu().numpy())\n",
    "    #         y_true.extend(target.cpu().numpy())\n",
    "            \n",
    "    # Accumulate predictions and targets\n",
    "    y_pred, y_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            y_pred.append(output.argmax(dim=1).cpu())\n",
    "            y_true.append(target.cpu())\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    y_true = torch.cat(y_true)\n",
    "    y_pred = torch.cat(y_pred)\n",
    "\n",
    "    # Calculate the loss for each sample\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')  # Set reduction='none' to get the loss per sample\n",
    "    loss_per_sample = criterion(y_pred, y_true).cpu()\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    precision_per_class = []\n",
    "    recall_per_class = []\n",
    "    f1_per_class = []\n",
    "    accuracy_per_class = []\n",
    "    loss_per_class = []\n",
    "\n",
    "    # Iterate through each class (for MNIST, classes are 0 to 9)\n",
    "    for class_idx in range(model.num_classes):\n",
    "        # Get all predictions and ground truths for the current class\n",
    "        class_mask = (y_true == class_idx)  # Mask for this class\n",
    "        \n",
    "        y_true_class = (y_true == class_idx)  # Convert to binary for the current class\n",
    "        y_pred_class = (y_pred == class_idx)  # Convert to binary for the current class\n",
    "        \n",
    "        # Compute precision, recall, and F1-score for this class (treat as binary classification)\n",
    "        precision = precision_score(y_true_class, y_pred_class, average='binary', pos_label=1)\n",
    "        recall = recall_score(y_true_class, y_pred_class, average='binary', pos_label=1)\n",
    "        f1 = f1_score(y_true_class, y_pred_class, average='binary', pos_label=1)\n",
    "        accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "        \n",
    "        # Compute the loss for this class (average the loss of samples in this class)\n",
    "        class_loss = loss_per_sample[class_mask].mean().item() if class_mask.sum() > 0 else 0\n",
    "        \n",
    "        # Append metrics to the lists\n",
    "        precision_per_class.append(precision)\n",
    "        recall_per_class.append(recall)\n",
    "        f1_per_class.append(f1)\n",
    "        accuracy_per_class.append(accuracy)\n",
    "        loss_per_class.append(class_loss)\n",
    "        \n",
    "    return precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class\n",
    "\n",
    "# Evaluate the model\n",
    "precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class = client_enhanced_evaluation(model, device, test_loader)\n",
    "print(f\"Precision per class: {precision_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 84])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the last layer weights\n",
    "model.fc3.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet-9 (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.393180\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.125153\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.061068\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.140412\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.020400\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.041769\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.004259\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.029730\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.007122\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.084373\n",
      "\n",
      "Test set: Average loss: 0.0489, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.074853\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.016679\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.052707\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.055934\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.004753\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.023614\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.115123\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.003418\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.018911\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.004706\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.020622\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.004132\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000469\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.003857\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.019780\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.016303\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.004763\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.053840\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.085678\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.030130\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 9923/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001537\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.013710\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.006243\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.019015\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.004558\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.013583\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.002078\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.000520\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.009588\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.007469\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 9942/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001560\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000405\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000278\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.001224\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.038621\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.004806\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000261\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.001285\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.014120\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 9952/10000 (100%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001588\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000224\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000305\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.000154\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.000201\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.004838\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000901\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000097\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000648\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.000989\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 9956/10000 (100%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.001478\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.000111\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.001215\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.001083\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000181\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.000939\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000340\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.020601\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.000151\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.007565\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 9946/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000060\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000072\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000316\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.077998\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.001265\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.003571\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000080\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000818\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000254\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.004676\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 9943/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000207\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000062\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000029\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000058\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000203\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000093\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000224\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000728\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000062\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.001300\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 9941/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000113\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.000358\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.002204\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.000817\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.000080\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.000959\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000054\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.000070\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000045\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.002585\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 9913/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the conv_bn_relu_pool function\n",
    "def conv_bn_relu_pool(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    ]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.prep = conv_bn_relu_pool(in_channels, 64)\n",
    "        self.layer1_head = conv_bn_relu_pool(64, 128, pool=True)\n",
    "        self.layer1_residual = nn.Sequential(conv_bn_relu_pool(128, 128), conv_bn_relu_pool(128, 128))\n",
    "        self.layer2 = conv_bn_relu_pool(128, 256, pool=True)\n",
    "        self.layer3_head = conv_bn_relu_pool(256, 512, pool=True)\n",
    "        self.layer3_residual = nn.Sequential(conv_bn_relu_pool(512, 512), conv_bn_relu_pool(512, 512))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Changed to adaptive average pooling:         self.MaxPool2d = nn.Sequential(nn.MaxPool2d(4))\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        x = self.layer1_head(x)\n",
    "        x = self.layer1_residual(x) + x\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3_head(x)\n",
    "        x = self.layer3_residual(x) + x\n",
    "        x = self.avgpool(x)  # Changed to adaptive average pooling\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Define a function to train the model\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Define a function to test the model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "\n",
    "# Main function to run the training and testing\n",
    "def main():\n",
    "    # Training settings\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    no_cuda = False\n",
    "    seed = 1\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    model = ResNet9(in_channels=1, num_classes=10).to(device)  # Set in_channels to 1 for MNIST\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5 model has 61,706 parameters\n",
      "ResNet-9 model has 6,573,705 parameters\n"
     ]
    }
   ],
   "source": [
    "# model parameters\n",
    "model_lenet = LeNet5()\n",
    "print(f'LeNet-5 model has {sum(p.numel() for p in model_lenet.parameters()):,} parameters')\n",
    "model_resnet9 = ResNet9(in_channels=1, num_classes=9)\n",
    "print(f'ResNet-9 model has {sum(p.numel() for p in model_resnet9.parameters()):,} parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainings on ours dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m\n\u001b[1;32m     21\u001b[0m     clients_data \u001b[38;5;241m=\u001b[39m noniidgen\u001b[38;5;241m.\u001b[39msplit_feature_skew(\n\u001b[1;32m     22\u001b[0m         train_features \u001b[38;5;241m=\u001b[39m train_images,\n\u001b[1;32m     23\u001b[0m         train_labels \u001b[38;5;241m=\u001b[39m train_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m         random_order \u001b[38;5;241m=\u001b[39m random_order\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clients_data\n\u001b[0;32m---> 39\u001b[0m data_MNIST \u001b[38;5;241m=\u001b[39m \u001b[43mdata_creation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMNIST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m data_FMNIST \u001b[38;5;241m=\u001b[39m data_creation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFMNIST\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m data_CIFAR10 \u001b[38;5;241m=\u001b[39m data_creation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m, in \u001b[0;36mdata_creation\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m random_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Run split_feature_skew\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m clients_data \u001b[38;5;241m=\u001b[39m \u001b[43mnoniidgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_feature_skew\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_number\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclient_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mset_rotation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mset_rotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrotations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_rotation_low\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_rotation_low\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_rotation_high\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_rotation_high\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mset_color\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mset_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_color_low\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_color_low\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_color_high\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_color_high\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_order\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_order\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clients_data\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-USI/PC/Desktop/USI_Locale/CFL/non_iiddata_generator_no_drifting.py:483\u001b[0m, in \u001b[0;36msplit_feature_skew\u001b[0;34m(train_features, train_labels, test_features, test_labels, client_number, set_rotation, rotations, scaling_rotation_low, scaling_rotation_high, set_color, colors, scaling_color_low, scaling_color_high, random_order, show_distribution)\u001b[0m\n\u001b[1;32m    480\u001b[0m         train_rotations \u001b[38;5;241m=\u001b[39m total_rotations[:len_train]\n\u001b[1;32m    481\u001b[0m         test_rotations \u001b[38;5;241m=\u001b[39m total_rotations[len_train:]\n\u001b[0;32m--> 483\u001b[0m         client_data_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrotate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_data_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_rotations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m         client_data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m rotate_dataset(client_data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m], test_rotations)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_color:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-USI/PC/Desktop/USI_Locale/CFL/non_iiddata_generator_no_drifting.py:162\u001b[0m, in \u001b[0;36mrotate_dataset\u001b[0;34m(dataset, degrees)\u001b[0m\n\u001b[1;32m    159\u001b[0m     rotated_img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mrotate(degree)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Convert the PIL image back to a tensor\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     rotated_img_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrotated_img\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    164\u001b[0m     rotated_images\u001b[38;5;241m.\u001b[39mappend(rotated_img_tensor)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Stack all tensors into a single tensor\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torchvision/transforms/functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    167\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mbyteorder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlittle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16B\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m--> 168\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    171\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/PIL/Image.py:742\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/PIL/Image.py:808\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# unpack data\u001b[39;00m\n\u001b[0;32m--> 808\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43m_getencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m e\u001b[38;5;241m.\u001b[39msetimage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim)\n\u001b[1;32m    811\u001b[0m bufsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m65536\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m)  \u001b[38;5;66;03m# see RawEncode.c\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/PIL/Image.py:449\u001b[0m, in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder(mode, \u001b[38;5;241m*\u001b[39margs \u001b[38;5;241m+\u001b[39m extra)\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getencoder\u001b[39m(\n\u001b[1;32m    450\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m, encoder_name: \u001b[38;5;28mstr\u001b[39m, args: Any, extra: \u001b[38;5;28mtuple\u001b[39m[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m    451\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core\u001b[38;5;241m.\u001b[39mImagingEncoder \u001b[38;5;241m|\u001b[39m ImageFile\u001b[38;5;241m.\u001b[39mPyEncoder:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# tweak arguments\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         args \u001b[38;5;241m=\u001b[39m ()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import non_iiddata_generator_no_drifting as noniidgen\n",
    "\n",
    "def data_creation(dataset_name):\n",
    "    # Load the dataset\n",
    "    # Options: \"MNIST\", \"FMNIST\", \"CIFAR10\", \"CIFAR100\", etc.\n",
    "    train_images, train_labels, test_images, test_labels = noniidgen.load_full_datasets(dataset_name)\n",
    "\n",
    "    # Define parameters for split_feature_skew\n",
    "    client_number = 10\n",
    "    set_rotation = True\n",
    "    rotations = 4\n",
    "    scaling_rotation_low = 0.1\n",
    "    scaling_rotation_high = 0.2\n",
    "    set_color = True\n",
    "    colors = 3\n",
    "    scaling_color_low = 0.1\n",
    "    scaling_color_high = 0.2\n",
    "    random_order = True\n",
    "\n",
    "    # Run split_feature_skew\n",
    "    clients_data = noniidgen.split_feature_skew(\n",
    "        train_features = train_images,\n",
    "        train_labels = train_labels,\n",
    "        test_features = test_images,\n",
    "        test_labels = test_labels,\n",
    "        client_number = client_number,\n",
    "        set_rotation = set_rotation,\n",
    "        rotations = rotations,\n",
    "        scaling_rotation_low = scaling_rotation_low,\n",
    "        scaling_rotation_high = scaling_rotation_high,\n",
    "        set_color = set_color,\n",
    "        colors = colors,\n",
    "        scaling_color_low = scaling_color_low,\n",
    "        scaling_color_high = scaling_color_high,\n",
    "        random_order = random_order\n",
    "    )\n",
    "    return clients_data\n",
    "\n",
    "data_MNIST = data_creation(\"MNIST\")\n",
    "data_FMNIST = data_creation(\"FMNIST\")\n",
    "data_CIFAR10 = data_creation(\"CIFAR10\")\n",
    "data_CIFAR100 = data_creation(\"CIFAR100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.492195\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.239441\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.164107\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.944633\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.713479\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.004442\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.913772\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.762644\n",
      "\n",
      "Test set: Average loss: 1.7305, Accuracy: 3724/10000 (37%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.895573\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.940766\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.958923\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.622462\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.713544\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.967214\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.407248\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.528836\n",
      "\n",
      "Test set: Average loss: 1.6656, Accuracy: 4110/10000 (41%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.456856\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.339177\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.494506\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.454145\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.425265\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.579947\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.543551\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.415182\n",
      "\n",
      "Test set: Average loss: 1.3105, Accuracy: 5354/10000 (54%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.602923\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.366930\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.235944\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.298732\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.094521\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.063001\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.243723\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.839254\n",
      "\n",
      "Test set: Average loss: 1.3724, Accuracy: 5174/10000 (52%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.069730\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.102493\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.870357\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.016649\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.056112\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.993669\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.031552\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.192953\n",
      "\n",
      "Test set: Average loss: 1.1694, Accuracy: 5931/10000 (59%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.104963\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.062804\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.888746\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.868818\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.778530\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.829901\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.244481\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.305514\n",
      "\n",
      "Test set: Average loss: 1.1246, Accuracy: 6184/10000 (62%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.916303\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.939575\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.785785\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.640003\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.022498\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.894803\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.841459\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.588679\n",
      "\n",
      "Test set: Average loss: 1.0482, Accuracy: 6402/10000 (64%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.594068\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.634710\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.662204\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.488437\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.581229\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.622351\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.726629\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.768913\n",
      "\n",
      "Test set: Average loss: 1.0358, Accuracy: 6590/10000 (66%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.554226\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.646536\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.587347\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.523803\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.870944\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.717994\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.651073\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.620309\n",
      "\n",
      "Test set: Average loss: 1.1104, Accuracy: 6542/10000 (65%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.489968\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.509784\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.375537\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.410504\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.465466\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.478827\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.686940\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.423189\n",
      "\n",
      "Test set: Average loss: 1.1751, Accuracy: 6542/10000 (65%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import transforms\n",
    "from math import prod\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, features, labels, transform=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        y = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "def merge_data(data):\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "    for client_data in data:\n",
    "        train_features.append(client_data['train_features'])\n",
    "        train_labels.append(client_data['train_labels'])\n",
    "        test_features.append(client_data['test_features'])\n",
    "        test_labels.append(client_data['test_labels'])\n",
    "\n",
    "    # Concatenate all the data\n",
    "    train_features = torch.cat(train_features, dim=0)\n",
    "    train_labels = torch.cat(train_labels, dim=0)\n",
    "    test_features = torch.cat(test_features, dim=0)\n",
    "    test_labels = torch.cat(test_labels, dim=0)\n",
    "\n",
    "    return train_features, train_labels, test_features, test_labels\n",
    "    \n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10, input_size=(28, 28)):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "        # Calculate the size of the features after convolutional layers\n",
    "        dummy_input = torch.zeros(1, in_channels, *input_size)\n",
    "        dummy_output = self.pool2(self.conv2(self.pool1(self.conv1(dummy_input))))\n",
    "        self.feature_size = prod(dummy_output.size()[1:])\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.feature_size, 120)  # Fully connected layer, output size 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "        x = self.pool1(x)  # Apply subsampling pool1\n",
    "        x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "        x = self.pool2(x)  # Apply subsampling pool2\n",
    "        x = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU after fc1\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Define a function to train the model\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Define a function to test the model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "    \n",
    "# define device\n",
    "def check_gpu(manual_seed=True, print_info=True):\n",
    "    if manual_seed:\n",
    "        torch.manual_seed(0)\n",
    "    if torch.cuda.is_available():\n",
    "        if print_info:\n",
    "            print(\"CUDA is available\")\n",
    "        device = 'cuda'\n",
    "        torch.cuda.manual_seed_all(0) \n",
    "    elif torch.backends.mps.is_available():\n",
    "        if print_info:\n",
    "            print(\"MPS is available\")\n",
    "        device = torch.device(\"mps\")\n",
    "        torch.mps.manual_seed(0)\n",
    "    else:\n",
    "        if print_info:\n",
    "            print(\"CUDA is not available\")\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "# Main function to run the training and testing\n",
    "def main():\n",
    "    # Training settings\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    no_cuda = False\n",
    "    seed = 1\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # merge the data\n",
    "    train_features, train_labels, test_features, test_labels = merge_data(data_CIFAR10)\n",
    "\n",
    "    # Define any necessary transforms\n",
    "    transform = None\n",
    "\n",
    "    # Create the datasets\n",
    "    train_dataset = CombinedDataset(train_features, train_labels, transform=transform)\n",
    "    test_dataset = CombinedDataset(test_features, test_labels, transform=transform)\n",
    "\n",
    "    # Define batch sizes\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "\n",
    "    # Create the data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    # model = LeNet5(in_channels=3, num_classes=10, input_size=(32,32)).to(device)\n",
    "    model = ResNet9(in_channels=3, num_classes=10).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples with our models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.311269\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.299786\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.297932\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.296077\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.280352\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.140450\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.250665\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.247782\n",
      "\n",
      "Test set: Average loss: 2.1686, Accuracy: 2076/10000 (21%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.215068\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 2.160078\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.154256\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 2.040477\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 2.118145\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 2.168162\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 2.121017\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 2.161525\n",
      "\n",
      "Test set: Average loss: 2.0218, Accuracy: 2659/10000 (27%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.162241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m         simple_test(model, device, test_loader)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 72\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, momentum\u001b[38;5;241m=\u001b[39mmomentum)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m     \u001b[43msimple_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     simple_test(model, device, test_loader)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-USI/PC/Desktop/USI_Locale/cfl_maggio/models.py:135\u001b[0m, in \u001b[0;36msimple_train\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m    133\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    134\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m--> 135\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    137\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "import non_iiddata_generator_no_drifting as noniidgen\n",
    "from non_iiddata_generator_no_drifting import merge_data\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    model_name = \"LeNet5\"   # Options: \"LeNet5\", \"ResNet9\"\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    seed = 1\n",
    "    transform = None\n",
    "    # dataset settings\n",
    "    dataset_name = \"CIFAR10\"\n",
    "    client_number = 10\n",
    "    set_rotation = True\n",
    "    rotations = 4\n",
    "    scaling_rotation_low = 0.1\n",
    "    scaling_rotation_high = 0.2\n",
    "    set_color = True\n",
    "    colors = 3\n",
    "    scaling_color_low = 0.1\n",
    "    scaling_color_high = 0.2\n",
    "    random_order = True\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # load data \n",
    "    train_images, train_labels, test_images, test_labels = noniidgen.load_full_datasets(dataset_name)\n",
    "\n",
    "    # create data: split_feature_skew\n",
    "    clients_data = noniidgen.split_feature_skew(\n",
    "        train_features = train_images,\n",
    "        train_labels = train_labels,\n",
    "        test_features = test_images,\n",
    "        test_labels = test_labels,\n",
    "        client_number = client_number,\n",
    "        set_rotation = set_rotation,\n",
    "        rotations = rotations,\n",
    "        scaling_rotation_low = scaling_rotation_low,\n",
    "        scaling_rotation_high = scaling_rotation_high,\n",
    "        set_color = set_color,\n",
    "        colors = colors,\n",
    "        scaling_color_low = scaling_color_low,\n",
    "        scaling_color_high = scaling_color_high,\n",
    "        random_order = random_order\n",
    "    )\n",
    "\n",
    "    # merge the data (for Centralized Learning Simulation)\n",
    "    train_features, train_labels, test_features, test_labels = merge_data(clients_data)\n",
    "\n",
    "    # Create the datasets\n",
    "    train_dataset = CombinedDataset(train_features, train_labels, transform=transform)\n",
    "    test_dataset = CombinedDataset(test_features, test_labels, transform=transform)\n",
    "\n",
    "    # Create the data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    # model = LeNet5(in_channels=3, num_classes=10, input_size=(32,32)).to(device)\n",
    "    model = models[model_name](in_channels=3, num_classes=10, input_size=(32,32)).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        simple_train(model, device, train_loader, optimizer, epoch)\n",
    "        simple_test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5 model has 83,126 parameters\n",
      "ResNet-9 model has 6,590,730 parameters\n",
      "LeNet-5 model has 62,006 parameters\n",
      "ResNet-9 model has 6,575,370 parameters\n"
     ]
    }
   ],
   "source": [
    "# print the number of parameters\n",
    "model_lenet = LeNet5(in_channels=3, num_classes=10, input_size=(32,32))\n",
    "print(f'LeNet-5 model has {sum(p.numel() for p in model_lenet.parameters()):,} parameters')\n",
    "model_resnet9 = ResNet9(in_channels=3, num_classes=10, input_size=(32,32))\n",
    "print(f'ResNet-9 model has {sum(p.numel() for p in model_resnet9.parameters()):,} parameters')\n",
    "\n",
    "model_lenet = LeNet5(in_channels=3, num_classes=10, input_size=(28,28))\n",
    "print(f'LeNet-5 model has {sum(p.numel() for p in model_lenet.parameters()):,} parameters')\n",
    "model_resnet9 = ResNet9(in_channels=3, num_classes=10, input_size=(28,28))\n",
    "print(f'ResNet-9 model has {sum(p.numel() for p in model_resnet9.parameters()):,} parameters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 0 [0/5000 (0%)]\tLoss: 2.305545\n",
      "Train Epoch: 0 [640/5000 (13%)]\tLoss: 2.302148\n",
      "Train Epoch: 0 [1280/5000 (25%)]\tLoss: 2.309596\n",
      "Train Epoch: 0 [1920/5000 (38%)]\tLoss: 2.300848\n",
      "Train Epoch: 0 [2560/5000 (51%)]\tLoss: 2.302197\n",
      "Train Epoch: 0 [3200/5000 (63%)]\tLoss: 2.310703\n",
      "Train Epoch: 0 [3840/5000 (76%)]\tLoss: 2.304026\n",
      "Train Epoch: 0 [4480/5000 (89%)]\tLoss: 2.303044\n",
      "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.303247\n",
      "Train Epoch: 1 [640/5000 (13%)]\tLoss: 2.304303\n",
      "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.296026\n",
      "Train Epoch: 1 [1920/5000 (38%)]\tLoss: 2.301974\n",
      "Train Epoch: 1 [2560/5000 (51%)]\tLoss: 2.303057\n",
      "Train Epoch: 1 [3200/5000 (63%)]\tLoss: 2.295039\n",
      "Train Epoch: 1 [3840/5000 (76%)]\tLoss: 2.297525\n",
      "Train Epoch: 1 [4480/5000 (89%)]\tLoss: 2.304764\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import models    \n",
    "import config as cfg\n",
    "import numpy as np\n",
    "import utils\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# check gpu and set manual seed\n",
    "device = utils.check_gpu(manual_seed=True)\n",
    "\n",
    "# model and history folder\n",
    "model = models.models[cfg.model_name](in_channels=3, num_classes=cfg.n_classes, input_size=cfg.input_size).to(device)\n",
    "# train_fn = utils.trainings[args.model]\n",
    "# evaluate_fn = utils.evaluations[args.model]\n",
    "# plot_fn = utils.plot_functions[args.model]\n",
    "# config = utils.config_tests[args.dataset][args.model]\n",
    "\n",
    "# check if metrics.csv exists otherwise delete it\n",
    "# utils.check_and_delete_metrics_file(config['history_folder'] + f\"client_{args.data_type}_{args.id}\", question=False)\n",
    "\n",
    "# load data\n",
    "data = np.load(f'./data/client_{1}.npy', allow_pickle=True).item()\n",
    "num_examples = data['train_features'].shape[0]\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = models.CombinedDataset(data['train_features'], data['train_labels'], transform=None)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True)\n",
    "\n",
    "# Optimizer and Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=cfg.lr, momentum=cfg.momentum)\n",
    "\n",
    "\n",
    "for epoch in range(2):\n",
    "                models.simple_train(model, device, train_loader, optimizer, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def get_parameters(model, config):\n",
    "        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "def set_parameters(model, parameters):\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_parameters(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_parameters(model, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CF_FL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
