{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5 (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.316792\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.817093\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.199695\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.175750\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.289238\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.158280\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.242588\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.081740\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.170460\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.120896\n",
      "\n",
      "Test set: Average loss: 0.0877, Accuracy: 9724/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.129914\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.121229\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.030282\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.111722\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.124593\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.014511\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.035954\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.031232\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.060888\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.062063\n",
      "\n",
      "Test set: Average loss: 0.0543, Accuracy: 9825/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.056323\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.065094\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.061783\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.040402\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.049720\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.029718\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.075228\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.010493\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.069095\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.005586\n",
      "\n",
      "Test set: Average loss: 0.0548, Accuracy: 9832/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the LeNet-5 architecture\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "        # These layers depend on the input size\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Fully connected layer, output size 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "        x = self.pool1(x)  # Apply subsampling pool1\n",
    "        x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "        x = self.pool2(x)  # Apply subsampling pool2\n",
    "        x = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU after fc1\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Define a function to train the model\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Define a function to test the model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "    \n",
    "# define device\n",
    "def check_gpu(manual_seed=True, print_info=True):\n",
    "    if manual_seed:\n",
    "        torch.manual_seed(0)\n",
    "    if torch.cuda.is_available():\n",
    "        if print_info:\n",
    "            print(\"CUDA is available\")\n",
    "        device = 'cuda'\n",
    "        torch.cuda.manual_seed_all(0) \n",
    "    elif torch.backends.mps.is_available():\n",
    "        if print_info:\n",
    "            print(\"MPS is available\")\n",
    "        device = torch.device(\"mps\")\n",
    "        torch.mps.manual_seed(0)\n",
    "    else:\n",
    "        if print_info:\n",
    "            print(\"CUDA is not available\")\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "# Main function to run the training and testing\n",
    "def main():\n",
    "    # Training settings\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 3\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    no_cuda = False\n",
    "    seed = 1\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    model = LeNet5(in_channels=1, num_classes=10).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.316792\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.817093\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.199695\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.175750\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.289238\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.158280\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.242588\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.081740\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.170460\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.120896\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "epochs = 1\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "no_cuda = False\n",
    "seed = 1\n",
    "\n",
    "device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "# Define the LeNet-5 architecture\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "        # These layers depend on the input size\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Fully connected layer, output size 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "        x = self.pool1(x)  # Apply subsampling pool1\n",
    "        x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "        x = self.pool2(x)  # Apply subsampling pool2\n",
    "        x = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU after fc1\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "model = LeNet5(in_channels=1, num_classes=10).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class-wise evaluation:\n",
      "Class 0: Precision = 0.9797, Recall = 0.9837, F1 = 0.9817, Accuracy = 0.9964, Loss = 0.0577\n",
      "Class 1: Precision = 0.9868, Recall = 0.9877, F1 = 0.9872, Accuracy = 0.9971, Loss = 0.0401\n",
      "Class 2: Precision = 0.9488, Recall = 0.9874, F1 = 0.9677, Accuracy = 0.9932, Loss = 0.0427\n",
      "Class 3: Precision = 0.9446, Recall = 0.9792, F1 = 0.9616, Accuracy = 0.9921, Loss = 0.0633\n",
      "Class 4: Precision = 0.9747, Recall = 0.9827, F1 = 0.9787, Accuracy = 0.9958, Loss = 0.0559\n",
      "Class 5: Precision = 0.9593, Recall = 0.9776, F1 = 0.9684, Accuracy = 0.9943, Loss = 0.0750\n",
      "Class 6: Precision = 0.9874, Recall = 0.9781, F1 = 0.9827, Accuracy = 0.9967, Loss = 0.0676\n",
      "Class 7: Precision = 0.9792, Recall = 0.9601, F1 = 0.9695, Accuracy = 0.9938, Loss = 0.1321\n",
      "Class 8: Precision = 0.9788, Recall = 0.9476, F1 = 0.9630, Accuracy = 0.9929, Loss = 0.1553\n",
      "Class 9: Precision = 0.9865, Recall = 0.9386, F1 = 0.9619, Accuracy = 0.9925, Loss = 0.1915\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def evaluate_model_per_class(model, device, test_loader, num_classes=10):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Define the cross-entropy loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    precision_per_class = [0] * num_classes\n",
    "    recall_per_class = [0] * num_classes\n",
    "    f1_per_class = [0] * num_classes\n",
    "    accuracy_per_class = [0] * num_classes\n",
    "    loss_per_class = [0] * num_classes\n",
    "    class_counts = [0] * num_classes\n",
    "\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    loss_all = []\n",
    "\n",
    "    # Accumulate predictions and targets over batches\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get model predictions\n",
    "            output = model(data)\n",
    "            y_pred_batch = output.argmax(dim=1, keepdim=False)  # Predicted class labels\n",
    "            \n",
    "            # Store the true and predicted labels for the batch\n",
    "            y_true_all.extend(target.cpu().numpy())\n",
    "            y_pred_all.extend(y_pred_batch.cpu().numpy())\n",
    "            \n",
    "            # Compute per-sample loss for the batch\n",
    "            batch_loss = criterion(output, target).cpu().numpy()\n",
    "            loss_all.extend(batch_loss)\n",
    "\n",
    "    # Convert collected predictions and true labels into tensors for processing\n",
    "    y_true_all = torch.tensor(y_true_all)\n",
    "    y_pred_all = torch.tensor(y_pred_all)\n",
    "    loss_all = torch.tensor(loss_all)\n",
    "\n",
    "    # Iterate through each class (for MNIST, classes are 0 to 9 by default)\n",
    "    for class_idx in range(num_classes):\n",
    "        # Get all predictions and ground truths for the current class\n",
    "        class_mask = (y_true_all == class_idx)  # Mask for this class\n",
    "        \n",
    "        y_true_class = (y_true_all == class_idx).numpy().astype(int)  # Binary labels for the current class\n",
    "        y_pred_class = (y_pred_all == class_idx).numpy().astype(int)  # Binary predictions for the current class\n",
    "        \n",
    "        # Only calculate if there are samples for this class\n",
    "        if class_mask.sum() > 0:\n",
    "            # Compute precision, recall, and F1-score for this class\n",
    "            precision = precision_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            recall = recall_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            f1 = f1_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "\n",
    "            # Compute the loss for this class (average the loss of samples in this class)\n",
    "            class_loss = loss_all[class_mask].mean().item()\n",
    "\n",
    "            # Update class counts and metrics\n",
    "            precision_per_class[class_idx] = precision\n",
    "            recall_per_class[class_idx] = recall\n",
    "            f1_per_class[class_idx] = f1\n",
    "            accuracy_per_class[class_idx] = accuracy\n",
    "            loss_per_class[class_idx] = class_loss\n",
    "            class_counts[class_idx] = class_mask.sum().item()\n",
    "\n",
    "    return precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class\n",
    "\n",
    "precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class, loss_all = evaluate_model_per_class(model, device, test_loader)\n",
    "print(\"Class-wise evaluation:\")\n",
    "for class_idx in range(10):\n",
    "    print(f\"Class {class_idx}: Precision = {precision_per_class[class_idx]:.4f}, Recall = {recall_per_class[class_idx]:.4f}, F1 = {f1_per_class[class_idx]:.4f}, Accuracy = {accuracy_per_class[class_idx]:.4f}, Loss = {loss_per_class[class_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1629e-03, 1.5663e-04, 5.1977e-03,  ..., 7.3909e-06, 3.2062e-04,\n",
       "        8.0701e-05])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class \u001b[38;5;241m=\u001b[39m \u001b[43mclient_enhanced_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision per class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision_per_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 28\u001b[0m, in \u001b[0;36mclient_enhanced_evaluation\u001b[0;34m(model, device, test_loader)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate the loss for each sample\u001b[39;00m\n\u001b[1;32m     27\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Set reduction='none' to get the loss per sample\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m loss_per_sample \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Initialize storage for metrics\u001b[39;00m\n\u001b[1;32m     31\u001b[0m precision_per_class \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/modules/loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# client-enhanced evaluation function\n",
    "def client_enhanced_evaluation(model, device, test_loader):\n",
    "    model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     for data, target in test_loader:\n",
    "    #         data, target = data.to(device), target.to(device)\n",
    "    #         output = model(data)\n",
    "    #         y_pred.extend(output.argmax(dim=1, keepdim=True).cpu().numpy())\n",
    "    #         y_true.extend(target.cpu().numpy())\n",
    "            \n",
    "    # Accumulate predictions and targets\n",
    "    y_pred, y_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            y_pred.append(output.argmax(dim=1).cpu())\n",
    "            y_true.append(target.cpu())\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    y_true = torch.cat(y_true)\n",
    "    y_pred = torch.cat(y_pred)\n",
    "\n",
    "    # Calculate the loss for each sample\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')  # Set reduction='none' to get the loss per sample\n",
    "    loss_per_sample = criterion(y_pred, y_true).cpu()\n",
    "\n",
    "    # Initialize storage for metrics\n",
    "    precision_per_class = []\n",
    "    recall_per_class = []\n",
    "    f1_per_class = []\n",
    "    accuracy_per_class = []\n",
    "    loss_per_class = []\n",
    "\n",
    "    # Iterate through each class (for MNIST, classes are 0 to 9)\n",
    "    for class_idx in range(model.num_classes):\n",
    "        # Get all predictions and ground truths for the current class\n",
    "        class_mask = (y_true == class_idx)  # Mask for this class\n",
    "        \n",
    "        y_true_class = (y_true == class_idx)  # Convert to binary for the current class\n",
    "        y_pred_class = (y_pred == class_idx)  # Convert to binary for the current class\n",
    "        \n",
    "        # Compute precision, recall, and F1-score for this class (treat as binary classification)\n",
    "        precision = precision_score(y_true_class, y_pred_class, average='binary', pos_label=1)\n",
    "        recall = recall_score(y_true_class, y_pred_class, average='binary', pos_label=1)\n",
    "        f1 = f1_score(y_true_class, y_pred_class, average='binary', pos_label=1)\n",
    "        accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "        \n",
    "        # Compute the loss for this class (average the loss of samples in this class)\n",
    "        class_loss = loss_per_sample[class_mask].mean().item() if class_mask.sum() > 0 else 0\n",
    "        \n",
    "        # Append metrics to the lists\n",
    "        precision_per_class.append(precision)\n",
    "        recall_per_class.append(recall)\n",
    "        f1_per_class.append(f1)\n",
    "        accuracy_per_class.append(accuracy)\n",
    "        loss_per_class.append(class_loss)\n",
    "        \n",
    "    return precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class\n",
    "\n",
    "# Evaluate the model\n",
    "precision_per_class, recall_per_class, f1_per_class, accuracy_per_class, loss_per_class = client_enhanced_evaluation(model, device, test_loader)\n",
    "print(f\"Precision per class: {precision_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 84])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the last layer weights\n",
    "model.fc3.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet-9 (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.393180\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.125153\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.061068\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.140412\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.020400\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.041769\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.004259\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.029730\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.007122\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.084373\n",
      "\n",
      "Test set: Average loss: 0.0489, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.074853\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.016679\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.052707\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.055934\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.004753\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.023614\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.115123\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.003418\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.018911\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.004706\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.020622\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.004132\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000469\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.003857\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.019780\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.016303\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.004763\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.053840\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.085678\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.030130\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 9923/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001537\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.013710\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.006243\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.019015\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.004558\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.013583\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.002078\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.000520\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.009588\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.007469\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 9942/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001560\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000405\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000278\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.001224\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.038621\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.004806\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000261\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000063\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.001285\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.014120\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 9952/10000 (100%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001588\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000224\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000305\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.000154\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.000201\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.004838\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000901\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000097\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000648\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.000989\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 9956/10000 (100%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.001478\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.000111\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.001215\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.001083\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000181\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.000939\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000340\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.020601\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.000151\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.007565\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 9946/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000060\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000072\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000316\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.077998\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.001265\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.003571\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000080\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000818\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000254\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.004676\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 9943/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000207\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000062\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000029\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000058\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000203\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000093\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000224\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000728\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000062\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.001300\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 9941/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000113\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.000358\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.002204\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.000817\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.000080\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.000959\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000054\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.000070\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000045\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.002585\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 9913/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the conv_bn_relu_pool function\n",
    "def conv_bn_relu_pool(in_channels, out_channels, pool=False):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    ]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.prep = conv_bn_relu_pool(in_channels, 64)\n",
    "        self.layer1_head = conv_bn_relu_pool(64, 128, pool=True)\n",
    "        self.layer1_residual = nn.Sequential(conv_bn_relu_pool(128, 128), conv_bn_relu_pool(128, 128))\n",
    "        self.layer2 = conv_bn_relu_pool(128, 256, pool=True)\n",
    "        self.layer3_head = conv_bn_relu_pool(256, 512, pool=True)\n",
    "        self.layer3_residual = nn.Sequential(conv_bn_relu_pool(512, 512), conv_bn_relu_pool(512, 512))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Changed to adaptive average pooling:         self.MaxPool2d = nn.Sequential(nn.MaxPool2d(4))\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        x = self.layer1_head(x)\n",
    "        x = self.layer1_residual(x) + x\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3_head(x)\n",
    "        x = self.layer3_residual(x) + x\n",
    "        x = self.avgpool(x)  # Changed to adaptive average pooling\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# Define a function to train the model\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Define a function to test the model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "\n",
    "# Main function to run the training and testing\n",
    "def main():\n",
    "    # Training settings\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    no_cuda = False\n",
    "    seed = 1\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    model = ResNet9(in_channels=1, num_classes=10).to(device)  # Set in_channels to 1 for MNIST\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5 model has 61,706 parameters\n",
      "ResNet-9 model has 6,573,705 parameters\n"
     ]
    }
   ],
   "source": [
    "# model parameters\n",
    "model_lenet = LeNet5()\n",
    "print(f'LeNet-5 model has {sum(p.numel() for p in model_lenet.parameters()):,} parameters')\n",
    "model_resnet9 = ResNet9(in_channels=1, num_classes=9)\n",
    "print(f'ResNet-9 model has {sum(p.numel() for p in model_resnet9.parameters()):,} parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainings on ours dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m\n\u001b[1;32m     21\u001b[0m     clients_data \u001b[38;5;241m=\u001b[39m noniidgen\u001b[38;5;241m.\u001b[39msplit_feature_skew(\n\u001b[1;32m     22\u001b[0m         train_features \u001b[38;5;241m=\u001b[39m train_images,\n\u001b[1;32m     23\u001b[0m         train_labels \u001b[38;5;241m=\u001b[39m train_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m         random_order \u001b[38;5;241m=\u001b[39m random_order\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clients_data\n\u001b[0;32m---> 39\u001b[0m data_MNIST \u001b[38;5;241m=\u001b[39m \u001b[43mdata_creation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMNIST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m data_FMNIST \u001b[38;5;241m=\u001b[39m data_creation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFMNIST\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m data_CIFAR10 \u001b[38;5;241m=\u001b[39m data_creation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m, in \u001b[0;36mdata_creation\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m random_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Run split_feature_skew\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m clients_data \u001b[38;5;241m=\u001b[39m \u001b[43mnoniidgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_feature_skew\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_number\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclient_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mset_rotation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mset_rotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrotations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_rotation_low\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_rotation_low\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_rotation_high\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_rotation_high\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mset_color\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mset_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_color_low\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_color_low\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_color_high\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_color_high\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_order\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_order\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clients_data\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-USI/PC/Desktop/USI_Locale/CFL/non_iiddata_generator_no_drifting.py:483\u001b[0m, in \u001b[0;36msplit_feature_skew\u001b[0;34m(train_features, train_labels, test_features, test_labels, client_number, set_rotation, rotations, scaling_rotation_low, scaling_rotation_high, set_color, colors, scaling_color_low, scaling_color_high, random_order, show_distribution)\u001b[0m\n\u001b[1;32m    480\u001b[0m         train_rotations \u001b[38;5;241m=\u001b[39m total_rotations[:len_train]\n\u001b[1;32m    481\u001b[0m         test_rotations \u001b[38;5;241m=\u001b[39m total_rotations[len_train:]\n\u001b[0;32m--> 483\u001b[0m         client_data_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrotate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_data_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_rotations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m         client_data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m rotate_dataset(client_data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m], test_rotations)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m set_color:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-USI/PC/Desktop/USI_Locale/CFL/non_iiddata_generator_no_drifting.py:162\u001b[0m, in \u001b[0;36mrotate_dataset\u001b[0;34m(dataset, degrees)\u001b[0m\n\u001b[1;32m    159\u001b[0m     rotated_img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mrotate(degree)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Convert the PIL image back to a tensor\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m     rotated_img_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrotated_img\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    164\u001b[0m     rotated_images\u001b[38;5;241m.\u001b[39mappend(rotated_img_tensor)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Stack all tensors into a single tensor\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/torchvision/transforms/functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    167\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mbyteorder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlittle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16B\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m--> 168\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    171\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/PIL/Image.py:742\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/PIL/Image.py:808\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# unpack data\u001b[39;00m\n\u001b[0;32m--> 808\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43m_getencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    809\u001b[0m e\u001b[38;5;241m.\u001b[39msetimage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim)\n\u001b[1;32m    811\u001b[0m bufsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m65536\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m)  \u001b[38;5;66;03m# see RawEncode.c\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/CFL/lib/python3.12/site-packages/PIL/Image.py:449\u001b[0m, in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder(mode, \u001b[38;5;241m*\u001b[39margs \u001b[38;5;241m+\u001b[39m extra)\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getencoder\u001b[39m(\n\u001b[1;32m    450\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m, encoder_name: \u001b[38;5;28mstr\u001b[39m, args: Any, extra: \u001b[38;5;28mtuple\u001b[39m[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m ()\n\u001b[1;32m    451\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core\u001b[38;5;241m.\u001b[39mImagingEncoder \u001b[38;5;241m|\u001b[39m ImageFile\u001b[38;5;241m.\u001b[39mPyEncoder:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# tweak arguments\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         args \u001b[38;5;241m=\u001b[39m ()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import non_iiddata_generator_no_drifting as noniidgen\n",
    "\n",
    "def data_creation(dataset_name):\n",
    "    # Load the dataset\n",
    "    # Options: \"MNIST\", \"FMNIST\", \"CIFAR10\", \"CIFAR100\", etc.\n",
    "    train_images, train_labels, test_images, test_labels = noniidgen.load_full_datasets(dataset_name)\n",
    "\n",
    "    # Define parameters for split_feature_skew\n",
    "    client_number = 10\n",
    "    set_rotation = True\n",
    "    rotations = 4\n",
    "    scaling_rotation_low = 0.1\n",
    "    scaling_rotation_high = 0.2\n",
    "    set_color = True\n",
    "    colors = 3\n",
    "    scaling_color_low = 0.1\n",
    "    scaling_color_high = 0.2\n",
    "    random_order = True\n",
    "\n",
    "    # Run split_feature_skew\n",
    "    clients_data = noniidgen.split_feature_skew(\n",
    "        train_features = train_images,\n",
    "        train_labels = train_labels,\n",
    "        test_features = test_images,\n",
    "        test_labels = test_labels,\n",
    "        client_number = client_number,\n",
    "        set_rotation = set_rotation,\n",
    "        rotations = rotations,\n",
    "        scaling_rotation_low = scaling_rotation_low,\n",
    "        scaling_rotation_high = scaling_rotation_high,\n",
    "        set_color = set_color,\n",
    "        colors = colors,\n",
    "        scaling_color_low = scaling_color_low,\n",
    "        scaling_color_high = scaling_color_high,\n",
    "        random_order = random_order\n",
    "    )\n",
    "    return clients_data\n",
    "\n",
    "data_MNIST = data_creation(\"MNIST\")\n",
    "data_FMNIST = data_creation(\"FMNIST\")\n",
    "data_CIFAR10 = data_creation(\"CIFAR10\")\n",
    "data_CIFAR100 = data_creation(\"CIFAR100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.492195\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.239441\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.164107\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.944633\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.713479\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.004442\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.913772\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.762644\n",
      "\n",
      "Test set: Average loss: 1.7305, Accuracy: 3724/10000 (37%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.895573\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.940766\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.958923\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.622462\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.713544\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.967214\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.407248\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.528836\n",
      "\n",
      "Test set: Average loss: 1.6656, Accuracy: 4110/10000 (41%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.456856\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.339177\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.494506\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.454145\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.425265\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.579947\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.543551\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.415182\n",
      "\n",
      "Test set: Average loss: 1.3105, Accuracy: 5354/10000 (54%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.602923\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.366930\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.235944\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.298732\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.094521\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.063001\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.243723\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.839254\n",
      "\n",
      "Test set: Average loss: 1.3724, Accuracy: 5174/10000 (52%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.069730\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.102493\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.870357\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.016649\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.056112\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.993669\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.031552\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.192953\n",
      "\n",
      "Test set: Average loss: 1.1694, Accuracy: 5931/10000 (59%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.104963\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.062804\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.888746\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.868818\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.778530\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.829901\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.244481\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.305514\n",
      "\n",
      "Test set: Average loss: 1.1246, Accuracy: 6184/10000 (62%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.916303\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.939575\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.785785\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.640003\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.022498\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.894803\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.841459\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.588679\n",
      "\n",
      "Test set: Average loss: 1.0482, Accuracy: 6402/10000 (64%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.594068\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.634710\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.662204\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.488437\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.581229\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.622351\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.726629\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.768913\n",
      "\n",
      "Test set: Average loss: 1.0358, Accuracy: 6590/10000 (66%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.554226\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.646536\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.587347\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.523803\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.870944\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.717994\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.651073\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.620309\n",
      "\n",
      "Test set: Average loss: 1.1104, Accuracy: 6542/10000 (65%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.489968\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.509784\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.375537\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.410504\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.465466\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.478827\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.686940\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.423189\n",
      "\n",
      "Test set: Average loss: 1.1751, Accuracy: 6542/10000 (65%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import transforms\n",
    "from math import prod\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, features, labels, transform=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        y = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "def merge_data(data):\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "    for client_data in data:\n",
    "        train_features.append(client_data['train_features'])\n",
    "        train_labels.append(client_data['train_labels'])\n",
    "        test_features.append(client_data['test_features'])\n",
    "        test_labels.append(client_data['test_labels'])\n",
    "\n",
    "    # Concatenate all the data\n",
    "    train_features = torch.cat(train_features, dim=0)\n",
    "    train_labels = torch.cat(train_labels, dim=0)\n",
    "    test_features = torch.cat(test_features, dim=0)\n",
    "    test_labels = torch.cat(test_labels, dim=0)\n",
    "\n",
    "    return train_features, train_labels, test_features, test_labels\n",
    "    \n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10, input_size=(28, 28)):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, stride=1, padding=2)  # Convolutional layer with 6 feature maps of size 5x5\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 6 feature maps of size 2x2\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # Convolutional layer with 16 feature maps of size 5x5\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)  # Subsampling layer with 16 feature maps of size 2x2\n",
    "        \n",
    "        # Calculate the size of the features after convolutional layers\n",
    "        dummy_input = torch.zeros(1, in_channels, *input_size)\n",
    "        dummy_output = self.pool2(self.conv2(self.pool1(self.conv1(dummy_input))))\n",
    "        self.feature_size = prod(dummy_output.size()[1:])\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.feature_size, 120)  # Fully connected layer, output size 120\n",
    "        self.fc2 = nn.Linear(120, 84)  # Fully connected layer, output size 84\n",
    "        self.fc3 = nn.Linear(84, num_classes)  # Fully connected layer, output size num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # Apply ReLU after conv1\n",
    "        x = self.pool1(x)  # Apply subsampling pool1\n",
    "        x = F.relu(self.conv2(x))  # Apply ReLU after conv2\n",
    "        x = self.pool2(x)  # Apply subsampling pool2\n",
    "        x = x.view(x.size(0), -1)  # Flatten for fully connected layers\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU after fc1\n",
    "        x = F.relu(self.fc2(x))  # Apply ReLU after fc2\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Define a function to train the model\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Define a function to test the model\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "    \n",
    "# define device\n",
    "def check_gpu(manual_seed=True, print_info=True):\n",
    "    if manual_seed:\n",
    "        torch.manual_seed(0)\n",
    "    if torch.cuda.is_available():\n",
    "        if print_info:\n",
    "            print(\"CUDA is available\")\n",
    "        device = 'cuda'\n",
    "        torch.cuda.manual_seed_all(0) \n",
    "    elif torch.backends.mps.is_available():\n",
    "        if print_info:\n",
    "            print(\"MPS is available\")\n",
    "        device = torch.device(\"mps\")\n",
    "        torch.mps.manual_seed(0)\n",
    "    else:\n",
    "        if print_info:\n",
    "            print(\"CUDA is not available\")\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "# Main function to run the training and testing\n",
    "def main():\n",
    "    # Training settings\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    no_cuda = False\n",
    "    seed = 1\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # merge the data\n",
    "    train_features, train_labels, test_features, test_labels = merge_data(data_CIFAR10)\n",
    "\n",
    "    # Define any necessary transforms\n",
    "    transform = None\n",
    "\n",
    "    # Create the datasets\n",
    "    train_dataset = CombinedDataset(train_features, train_labels, transform=transform)\n",
    "    test_dataset = CombinedDataset(test_features, test_labels, transform=transform)\n",
    "\n",
    "    # Define batch sizes\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "\n",
    "    # Create the data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    # model = LeNet5(in_channels=3, num_classes=10, input_size=(32,32)).to(device)\n",
    "    model = ResNet9(in_channels=3, num_classes=10).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples with our models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.311269\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.299786\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.297932\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.296077\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.280352\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.140450\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.250665\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.247782\n",
      "\n",
      "Test set: Average loss: 2.1686, Accuracy: 2076/10000 (21%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.215068\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 2.160078\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.154256\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 2.040477\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 2.118145\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 2.168162\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 2.121017\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 2.161525\n",
      "\n",
      "Test set: Average loss: 2.0218, Accuracy: 2659/10000 (27%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.162241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m         simple_test(model, device, test_loader)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 72\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, momentum\u001b[38;5;241m=\u001b[39mmomentum)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m     \u001b[43msimple_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     simple_test(model, device, test_loader)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-USI/PC/Desktop/USI_Locale/cfl_maggio/models.py:135\u001b[0m, in \u001b[0;36msimple_train\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m    133\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    134\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m--> 135\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    137\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniforge3/envs/CF_FL/lib/python3.12/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "import non_iiddata_generator_no_drifting as noniidgen\n",
    "from non_iiddata_generator_no_drifting import merge_data\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    model_name = \"LeNet5\"   # Options: \"LeNet5\", \"ResNet9\"\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    seed = 1\n",
    "    transform = None\n",
    "    # dataset settings\n",
    "    dataset_name = \"CIFAR10\"\n",
    "    client_number = 10\n",
    "    set_rotation = True\n",
    "    rotations = 4\n",
    "    scaling_rotation_low = 0.1\n",
    "    scaling_rotation_high = 0.2\n",
    "    set_color = True\n",
    "    colors = 3\n",
    "    scaling_color_low = 0.1\n",
    "    scaling_color_high = 0.2\n",
    "    random_order = True\n",
    "\n",
    "    device = check_gpu(manual_seed=True, print_info=True)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # load data \n",
    "    train_images, train_labels, test_images, test_labels = noniidgen.load_full_datasets(dataset_name)\n",
    "\n",
    "    # create data: split_feature_skew\n",
    "    clients_data = noniidgen.split_feature_skew(\n",
    "        train_features = train_images,\n",
    "        train_labels = train_labels,\n",
    "        test_features = test_images,\n",
    "        test_labels = test_labels,\n",
    "        client_number = client_number,\n",
    "        set_rotation = set_rotation,\n",
    "        rotations = rotations,\n",
    "        scaling_rotation_low = scaling_rotation_low,\n",
    "        scaling_rotation_high = scaling_rotation_high,\n",
    "        set_color = set_color,\n",
    "        colors = colors,\n",
    "        scaling_color_low = scaling_color_low,\n",
    "        scaling_color_high = scaling_color_high,\n",
    "        random_order = random_order\n",
    "    )\n",
    "\n",
    "    # merge the data (for Centralized Learning Simulation)\n",
    "    train_features, train_labels, test_features, test_labels = merge_data(clients_data)\n",
    "\n",
    "    # Create the datasets\n",
    "    train_dataset = CombinedDataset(train_features, train_labels, transform=transform)\n",
    "    test_dataset = CombinedDataset(test_features, test_labels, transform=transform)\n",
    "\n",
    "    # Create the data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    # model = LeNet5(in_channels=3, num_classes=10, input_size=(32,32)).to(device)\n",
    "    model = models[model_name](in_channels=3, num_classes=10, input_size=(32,32)).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        simple_train(model, device, train_loader, optimizer, epoch)\n",
    "        simple_test(model, device, test_loader)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet-5 model has 83,126 parameters\n",
      "ResNet-9 model has 6,590,730 parameters\n",
      "LeNet-5 model has 62,006 parameters\n",
      "ResNet-9 model has 6,575,370 parameters\n"
     ]
    }
   ],
   "source": [
    "# print the number of parameters\n",
    "model_lenet = LeNet5(in_channels=3, num_classes=10, input_size=(32,32))\n",
    "print(f'LeNet-5 model has {sum(p.numel() for p in model_lenet.parameters()):,} parameters')\n",
    "model_resnet9 = ResNet9(in_channels=3, num_classes=10, input_size=(32,32))\n",
    "print(f'ResNet-9 model has {sum(p.numel() for p in model_resnet9.parameters()):,} parameters')\n",
    "\n",
    "model_lenet = LeNet5(in_channels=3, num_classes=10, input_size=(28,28))\n",
    "print(f'LeNet-5 model has {sum(p.numel() for p in model_lenet.parameters()):,} parameters')\n",
    "model_resnet9 = ResNet9(in_channels=3, num_classes=10, input_size=(28,28))\n",
    "print(f'ResNet-9 model has {sum(p.numel() for p in model_resnet9.parameters()):,} parameters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Train Epoch: 0 [0/5000 (0%)]\tLoss: 2.305545\n",
      "Train Epoch: 0 [640/5000 (13%)]\tLoss: 2.302148\n",
      "Train Epoch: 0 [1280/5000 (25%)]\tLoss: 2.309596\n",
      "Train Epoch: 0 [1920/5000 (38%)]\tLoss: 2.300848\n",
      "Train Epoch: 0 [2560/5000 (51%)]\tLoss: 2.302197\n",
      "Train Epoch: 0 [3200/5000 (63%)]\tLoss: 2.310703\n",
      "Train Epoch: 0 [3840/5000 (76%)]\tLoss: 2.304026\n",
      "Train Epoch: 0 [4480/5000 (89%)]\tLoss: 2.303044\n",
      "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.303247\n",
      "Train Epoch: 1 [640/5000 (13%)]\tLoss: 2.304303\n",
      "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.296026\n",
      "Train Epoch: 1 [1920/5000 (38%)]\tLoss: 2.301974\n",
      "Train Epoch: 1 [2560/5000 (51%)]\tLoss: 2.303057\n",
      "Train Epoch: 1 [3200/5000 (63%)]\tLoss: 2.295039\n",
      "Train Epoch: 1 [3840/5000 (76%)]\tLoss: 2.297525\n",
      "Train Epoch: 1 [4480/5000 (89%)]\tLoss: 2.304764\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import models    \n",
    "import config as cfg\n",
    "import numpy as np\n",
    "import utils\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# check gpu and set manual seed\n",
    "device = utils.check_gpu(manual_seed=True)\n",
    "\n",
    "# model and history folder\n",
    "model = models.models[cfg.model_name](in_channels=3, num_classes=cfg.n_classes, input_size=cfg.input_size).to(device)\n",
    "# train_fn = utils.trainings[args.model]\n",
    "# evaluate_fn = utils.evaluations[args.model]\n",
    "# plot_fn = utils.plot_functions[args.model]\n",
    "# config = utils.config_tests[args.dataset][args.model]\n",
    "\n",
    "# check if metrics.csv exists otherwise delete it\n",
    "# utils.check_and_delete_metrics_file(config['history_folder'] + f\"client_{args.data_type}_{args.id}\", question=False)\n",
    "\n",
    "# load data\n",
    "data = np.load(f'./data/client_{1}.npy', allow_pickle=True).item()\n",
    "num_examples = data['train_features'].shape[0]\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = models.CombinedDataset(data['train_features'], data['train_labels'], transform=None)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True)\n",
    "\n",
    "# Optimizer and Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=cfg.lr, momentum=cfg.momentum)\n",
    "\n",
    "\n",
    "for epoch in range(2):\n",
    "                models.simple_train(model, device, train_loader, optimizer, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def get_parameters(model, config):\n",
    "        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "def set_parameters(model, parameters):\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_parameters(model, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_parameters(model, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CF_FL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
